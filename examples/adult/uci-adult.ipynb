{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546fa208-c19c-405b-81b1-cf99fcb4a830",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UCI Adult Dataset or Census Income\n",
    "\n",
    "This is a very popular ML task, with tabular data. The objective is to predict whether income exceeds $50K/yr based on census data. \n",
    "Also known as \"Census Income\" dataset.\n",
    "\n",
    "The data is old and biased on different ways ... but it can be used opaquely for ML experimentation.\n",
    "\n",
    "The source code of this example in one piece can be seen in the demo under [.../examples/adult/demo/](https://github.com/gomlx/gomlx/tree/main/examples/adult/demo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab071e3-227f-4c77-b864-2b7e5a5ccbdf",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general).\n",
    "\n",
    "For this example we are forcing it to use the CPU backend, even if there is a GPU available -- it is such a small model, not worth going to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba46cb6-059d-4387-876c-665f778f2447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/gopjrt\" to local directory \"/home/janpf/Projects/gopjrt\".\n"
     ]
    }
   ],
   "source": [
    "!*rm -f go.work && go work init && go work use . \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/gopjrt\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf991f-4fa5-4bae-8e49-ca67fb8dbd5b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "GoMLX provides [a simple `adult` library](https://pkg.go.dev/github.com/gomlx/gomlx/examples/adult) to facilitate downdoaling and preprocessing the data. Data is available in [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "After downloading the data and validating the checksum (both training and testing), it generates the quantiles for the continuous features, and the vocabularies for the categorical features. It saves all this info for faster restart later in a binary file. So this won't be necessary a second time.\n",
    "\n",
    "The quantiles are used to calibrate the values, using a piece-wise-lienar calibration, very good for these things. See [`layers.PieceWiseLinearCalibration` documentation](https://pkg.go.dev/github.com/gomlx/gomlx@v0.1.0/ml/layers#PieceWiseLinearCalibration).\n",
    "\n",
    "We create a flag `--data` to define the directory where to save the intermediary files: downloaded and preprocessed datasets.\n",
    "In this examle we set it to `~/work/uci-adult`. Verbosity can be contolled with the `--verbosity` flag. \n",
    "\n",
    "We set default in Go for these flags, but they can easily be reset for a new run by providing them after the `%%` Jupyter kernel meta-command -- in indicates that the subsequent lines should be put in to a `func main`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9418be86-70bc-41ad-9e0a-3a5e6bf52b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Categorical: (24.08% positive ratio, 23.86% weighted positive ratio)\n",
      "\tRow 0:\t[7 10 5 1 2 5 2 39]\n",
      "\tRow 1:\t[6 10 3 4 1 5 2 39]\n",
      "\tRow 2:\t[4 12 1 6 2 5 2 39]\n",
      "\t...\n",
      "\tRow 32558:\t[4 12 7 1 5 5 1 39]\n",
      "\tRow 32559:\t[4 12 5 1 4 5 2 39]\n",
      "\tRow 32560:\t[5 12 3 4 6 5 1 39]\n",
      "\n",
      "Sample Continuous:\n",
      "\tRow 0:\t[39 13 2174 0 40]\n",
      "\tRow 1:\t[50 13 0 0 13]\n",
      "\tRow 2:\t[38 9 0 0 40]\n",
      "\t...\n",
      "\tRow 32558:\t[58 9 0 0 40]\n",
      "\tRow 32559:\t[22 9 0 0 20]\n",
      "\tRow 32560:\t[52 9 15024 0 40]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flag\"\n",
    "    \n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    flagDataDir       = flag.String(\"data\", \"~/work/uci-adult\", \"Directory to save and load downloaded and generated dataset files.\")\n",
    "    flagVerbosity     = flag.Int(\"verbosity\", 0, \"Level of verbosity, the higher the more verbose.\")\n",
    "    flagForceDownload = flag.Bool(\"force_download\", false, \"Force re-download of Adult dataset files.\")\n",
    "    flagNumQuantiles  = flag.Int(\"quantiles\", 100, \"Max number of quantiles to use for numeric features, used during piece-wise linear calibration. It will only use unique values, so if there are fewer variability, fewer quantiles are used.\")\n",
    ")\n",
    "\n",
    "%% --verbosity=2\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdab7255-2224-496a-9ec7-75927150f9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 170M\n",
      "-rw-r--r-- 1 janpf janpf 3.8M Jul 20  2024 adult.data\n",
      "-rw-r--r-- 1 janpf janpf 2.0M Jul 20  2024 adult.test\n",
      "-rw-r--r-- 1 janpf janpf 1.3M Jul 20  2024 adult_data-100_quantiles.bin\n",
      "drwxr-xr-x 2 janpf janpf 4.0K Jun  4  2009 cifar-10-batches-bin\n",
      "-rw-r--r-- 1 janpf janpf 163M Aug 15  2024 cifar-10-binary.tar.gz\n",
      "drwxr-x--- 2 janpf janpf 4.0K Aug  2  2024 fnn\n",
      "drwxr-x--- 2 janpf janpf 4.0K Jul 21  2024 kan_baseline\n",
      "drwxr-x--- 2 janpf janpf 4.0K Feb 23  2025 test\n",
      "drwxr-x--- 2 janpf janpf 4.0K Jun 18 05:14 test_model\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/work/uci-adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1cd493-a81f-4c5f-9004-d21e95103f8e",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "This sets the the superset of hyperparameters with their default values that can be used by the model, by setting them in the context.\n",
    "\n",
    "See the [`demo/main.go`](https://github.com/gomlx/gomlx/blob/main/examples/adult/demo/main.go) file for how to add a flag to allow setting them from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d03e06-f375-4a68-8705-c9d3b6af81ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbatch_size=17\n",
      "\tfnn_num_hidden_layers=12\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/context\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/layers\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/layers/fnn\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/layers/kan\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/layers/regularizers\"\n",
    "    \"github.com/gomlx/gomlx/ui/commandline\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train/optimizers\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train/optimizers/cosineschedule\"\n",
    "\t\"github.com/janpfeifer/must\"    \n",
    ")\n",
    "\n",
    "// settings is bound to a \"-set\" flag to be used to set context hyperparameters.\n",
    "var settings = commandline.CreateContextSettingsFlag(createDefaultContext(), \"set\")\n",
    "\n",
    "func createDefaultContext() *context.Context {\n",
    "\tctx := context.New()\n",
    "\tctx.RngStateReset()\n",
    "\tctx.SetParams(map[string]any{\n",
    "\t\t\"train_steps\":     5000,\n",
    "\t\t\"batch_size\":      128,\n",
    "\t\t\"eval_batch_size\":      1000,\n",
    "\t\t\"plots\":           true,\n",
    "        \"num_checkpoints\": 3,\n",
    "\n",
    "\t\toptimizers.ParamOptimizer:           \"adam\",\n",
    "\t\toptimizers.ParamLearningRate:        0.001,\n",
    "\t\toptimizers.ParamAdamEpsilon:         1e-7,\n",
    "\t\toptimizers.ParamAdamDType:           \"\",\n",
    "\t\tcosineschedule.ParamPeriodSteps:     0,\n",
    "\t\tactivations.ParamActivation:         \"sigmoid\",\n",
    "\t\tlayers.ParamDropoutRate:             0.0,\n",
    "\t\tregularizers.ParamL2:                1e-5,\n",
    "\t\tregularizers.ParamL1:                1e-5,\n",
    "\n",
    "\t\t// FNN network parameters:\n",
    "\t\tfnn.ParamNumHiddenLayers: 1,\n",
    "\t\tfnn.ParamNumHiddenNodes:  4,\n",
    "\t\tfnn.ParamResidual:        true,\n",
    "\t\tfnn.ParamNormalization:   \"layer\",\n",
    "\n",
    "\t\t// KAN network parameters:\n",
    "\t\t\"kan\":                       false, // Enable kan\n",
    "\t\tkan.ParamNumControlPoints:   20,    // Number of control points\n",
    "\t\tkan.ParamNumHiddenNodes:     4,\n",
    "\t\tkan.ParamNumHiddenLayers:    1,\n",
    "\t\tkan.ParamBSplineDegree:      2,\n",
    "\t\tkan.ParamBSplineMagnitudeL1: 1e-5,\n",
    "\t\tkan.ParamBSplineMagnitudeL2: 0.0,\n",
    "\t\tkan.ParamDiscrete:           false,\n",
    "\t\tkan.ParamDiscreteSoftness:   0.1,\n",
    "\t})\n",
    "\treturn ctx\n",
    "}\n",
    "\n",
    "// contextFromSettings is the default context (createDefaultContext) changed by -set flag.\n",
    "func contextFromSettings() (ctx *context.Context, paramsSet []string) {\n",
    "    ctx = createDefaultContext()\n",
    "    paramsSet = must.M1(commandline.ParseContextSettings(ctx, *settings))\n",
    "    return\n",
    "}\n",
    "\n",
    "// Let's test that we can set hyperparameters by setting it in the \"-set\" flag:\n",
    "%% -set=\"batch_size=17;fnn_num_hidden_layers=12\"\n",
    "ctx, paramsSet := contextFromSettings()\n",
    "for _, name := range paramsSet {\n",
    "    if value, found := ctx.GetParam(name); found {\n",
    "        fmt.Printf(\"\\t%s=%v\\n\", name, value)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd4b781-3e38-41b2-8621-b4abbf2d6ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbatch_size=17\n",
      "\tfnn_num_hidden_layers=12\n"
     ]
    }
   ],
   "source": [
    "%% -set=\"batch_size=17;fnn_num_hidden_layers=12\"\n",
    "ctx, paramsSet := contextFromSettings()\n",
    "for _, name := range paramsSet {\n",
    "    if value, found := ctx.GetParam(name); found {\n",
    "        fmt.Printf(\"\\t%s=%v\\n\", name, value)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b783b-56f0-457c-b28e-7bb0dd7e94da",
   "metadata": {},
   "source": [
    "### Creating Datasets\n",
    "\n",
    "First we create the GoMLX's `backend`: it's the engine instance (XLA in this case) that \n",
    "compiles and executes our computation graph.\n",
    "\n",
    "It's needed to create tensors that will be fed to the accelearator (GPU or even CPU accelerated code)\n",
    "\n",
    "With that we create the samplers of data that we will use to train and evaluate. They implement \n",
    "GoMLX's `train.Dataset` interface, which is what is used by our training loop to draw batches to\n",
    "train, or our eval loop to draw batches to evaluate.\n",
    "\n",
    "The inputs are 3 tensors: *categorical values*, *continuous values* and *weights*.\n",
    "\n",
    "In the cell below we define `BuildDatasets` and printout some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13f771b-7109-49d2-8db5-5f3d5a91d324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: stablehlo - stablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "Inputs of batch (size 128):\n",
      "\tcategorical:\n",
      "\t\tFeatures=[workclass education marital-status occupation relationship race sex native-country]\n",
      "\t\tValues: [128][8]int64{\n",
      " {4, 10, 5, ..., 2, 2, 39},\n",
      " {4, 3, 3, ..., 5, 2, 39},\n",
      " {7, 16, 5, ..., 5, 1, 39},\n",
      " ...,\n",
      " {4, 10, 5, ..., 5, 1, 39},\n",
      " {6, 16, 3, ..., 5, 2, 39},\n",
      " {2, 8, 1, ..., 5, 1, 39}}\n",
      "\tcontinuous:\n",
      "\t\tFeatures=[age education-num capital-gain capital-loss hours-per-week]\n",
      "\t\tValues: [128][5]float32{\n",
      " {23, 13, 0, 0, 40},\n",
      " {23, 8, 0, 0, 40},\n",
      " {19, 10, 0, 0, 40},\n",
      " ...,\n",
      " {38, 13, 0, 0, 70},\n",
      " {42, 10, 0, 0, 55},\n",
      " {34, 12, 0, 0, 10}}\n",
      "\tweights: [128][1]float32{\n",
      " {1.351e+05},\n",
      " {2.112e+05},\n",
      " {1.653e+05},\n",
      " ...,\n",
      " {2.97e+05},\n",
      " {7.953e+04},\n",
      " {3.568e+04}}\n",
      "\n",
      "Labels of batch:\n",
      "\t[128][1]float32{\n",
      " {0},\n",
      " {0},\n",
      " {0},\n",
      " ...,\n",
      " {0},\n",
      " {1},\n",
      " {0}}\n",
      "\n",
      "Labels distributions:\n",
      "\tTrain:\t24.08% positive\n",
      "\tTest:\t23.62% positive\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flag\"\n",
    "    \"fmt\"\n",
    "    \"io\"\n",
    "\n",
    "    \"github.com/gomlx/gomlx/backends\"\n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train\"\n",
    "    \"github.com/gomlx/gomlx/pkg/core/tensors\"\n",
    "\n",
    "    _ \"github.com/gomlx/gomlx/backends/default\"\n",
    ")\n",
    "\n",
    "// Global backend created an initialization, used everywhere.\n",
    "var backend = backends.MustNew()\n",
    "\n",
    "// BuildDatasets returns 3 `train.Dataset`:\n",
    "// * trainingSampler is an endless random sampler used for training.\n",
    "// * trainingEvalSampler samples through exactly one epoch of the train dataset.\n",
    "// * testEvalSampler samples through exactly one epoch of the test dataset.\n",
    "func BuildDatasets(ctx *context.Context) (trainDS, trainEvalDS, testEvalDS train.Dataset) {\n",
    "\tbatchSize := context.GetParamOr(ctx, \"batch_size\", 128)\n",
    "\tevalBatchSize := context.GetParamOr(ctx, \"eval_batch_size\", 1000)\n",
    "    baseDS := adult.NewDataset(backend, adult.Data.Train, \"batched train\")\n",
    "    trainEvalDS = baseDS.Copy().BatchSize(evalBatchSize, false)\n",
    "    testEvalDS = adult.NewDataset(backend, adult.Data.Test, \"test\").\n",
    "        BatchSize(evalBatchSize, false)\n",
    "    // For training, we shuffle and loop indefinitely.\n",
    "    trainDS = baseDS.BatchSize(batchSize, true).Shuffle().Infinite(true)\n",
    "    return\n",
    "}\n",
    "\n",
    "// PositiveRatio finds out the the ratio of positive labels in the\n",
    "// training and testing data.\n",
    "//\n",
    "// We could do this easily with GoMLX computation model (just `ReduceAllSum`), but\n",
    "// this examples shows it's also ok to mix Go computations.\n",
    "func PositiveRatio(ds train.Dataset) float32 {\n",
    "    ds.Reset()  // Start from beginning.\n",
    "    var sum float32\n",
    "    var count float32\n",
    "    for {\n",
    "        _, _, labels, err := ds.Yield()\n",
    "        if err == io.EOF {\n",
    "            break;\n",
    "        }\n",
    "        if err != nil { panic(err) }\n",
    "        data := tensors.CopyFlatData[float32](labels[0])\n",
    "        for _, value := range data {\n",
    "            sum += value\n",
    "        }\n",
    "        count += float32(len(data))\n",
    "    }\n",
    "    return sum/count\n",
    "}\n",
    "\n",
    "%%\n",
    "fmt.Printf(\"Backend: %s - %s\\n\", backend, backend.Description())\n",
    "\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "ctx, _ := contextFromSettings()\n",
    "trainingDS, trainingEvalDS, testEvalDS := BuildDatasets(ctx)\n",
    "\n",
    "// Take one batch.\n",
    "_, inputs, labels, err := trainingDS.Yield()\n",
    "if err != nil { panic(err) }\n",
    "fmt.Printf(\"Inputs of batch (size %d):\\n\", context.GetParamOr(ctx, \"batch_size\", 0))\n",
    "fmt.Printf(\"\\tcategorical:\\n\\t\\tFeatures=%v\\n\", adult.Data.VocabulariesFeatures)\n",
    "fmt.Printf(\"\\t\\tValues: %s\\n\", inputs[0])\n",
    "fmt.Printf(\"\\tcontinuous:\\n\\t\\tFeatures=%v\\n\", adult.Data.QuantilesFeatures)\n",
    "fmt.Printf(\"\\t\\tValues: %s\\n\", inputs[1])\n",
    "fmt.Printf(\"\\tweights: %s\\n\", inputs[2])\n",
    "fmt.Printf(\"\\nLabels of batch:\\n\\t%s\\n\", labels[0])\n",
    "fmt.Printf(\"\\nLabels distributions:\\n\\tTrain:\\t%.2f%% positive\\n\\tTest:\\t%.2f%% positive\\n\",\n",
    "           PositiveRatio(trainingEvalDS)*100.0, PositiveRatio(testEvalDS)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efd046-bbd5-4f7d-94e0-9ed3c64512b1",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Lots of hyper-parameter flags, but otherwise a straight forward FNN, using piece-wise linear calibration of the continuous features, and embeddings for the categorical features.\n",
    "\n",
    "> **Note**: building models is a constant checking that shapes are compatible. It's a bit annoying, in particular because shapes are known in runtime only -- no compile time check. GoMLX tries to help providing a stack trace of where errors happen so one can pin-point issues quickly. But often it involves lots of experimentation (more than ordinary Go code).\n",
    ">\n",
    "> Developing with a Noteboook (see [GoNB](https://github.com/janpfeifer/gonb)) or simply a unit test on your\n",
    "> `ModelGraph` function are quick and convenient ways to develop models -- before actually training them.\n",
    "> You can also use shape asserts in the middle of the `ModelGraph`, as we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7040e63b-33f1-4ff9-a232-187196c5f9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=128: (Float32)[128 1]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"io\"\n",
    "\n",
    "    . \"github.com/gomlx/gomlx/pkg/core/graph\"\n",
    "\n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    "    \"github.com/gomlx/gomlx/pkg/core/shapes\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/context\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train/optimizers\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train/optimizers/cosineschedule\"\n",
    "    \"github.com/gomlx/gopjrt/dtypes\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    // ModelDType used for the model. Must match RawData Go types.\n",
    "    ModelDType = dtypes.Float32\n",
    "    \n",
    "\n",
    "    // Model hyperparameters.\n",
    "    flagUseCategorical       = flag.Bool(\"use_categorical\", true, \"Use categorical features.\")\n",
    "    flagUseContinuous        = flag.Bool(\"use_continuous\", true, \"Use continuous features.\")\n",
    "    flagTrainableCalibration = flag.Bool(\"trainable_calibration\", true, \"Allow piece-wise linear calibration to adjust outputs.\")\n",
    "    flagEmbeddingDim    = flag.Int(\"embedding_dim\", 8, \"Default embedding dimension for categorical values.\")\n",
    ")\n",
    "\n",
    "\n",
    "// ModelGraph outputs the logits (not the probabilities). The parameter inputs should contain 3 tensors:\n",
    "//\n",
    "// - categorical inputs, shaped  `(int64)[batch_size, len(VocabulariesFeatures)]`\n",
    "// - continuous inputs, shaped `(float32)[batch_size, len(Quantiles)]`\n",
    "// - weights: not currently used, but shaped `(float32)[batch_size, 1]`.\n",
    "func ModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\t_ = spec // Not used, since the dataset is always the same.\n",
    "\tg := inputs[0].Graph()\n",
    "\tdtype := inputs[1].DType() // From continuous features.\n",
    "    ctx = ctx.In(\"model\")\n",
    "    \n",
    "\t// Use Cosine schedule of the learning rate, if hyperparameter is set to a value > 0.\n",
    "\tcosineschedule.New(ctx, g, dtype).FromContext().Done()\n",
    "\n",
    "\tcategorical, continuous := inputs[0], inputs[1]\n",
    "\tbatchSize := categorical.Shape().Dimensions[0]\n",
    "\n",
    "\t// Feature preprocessing:\n",
    "\tvar allEmbeddings []*Node\n",
    "\tif *flagUseCategorical {\n",
    "\t\t// Embedding of categorical values, each with its own vocabulary.\n",
    "\t\tnumCategorical := categorical.Shape().Dimensions[1]\n",
    "\t\tfor catIdx := 0; catIdx < numCategorical; catIdx++ {\n",
    "\t\t\t// Take one column at a time of the categorical values.\n",
    "\t\t\tsplit := Slice(categorical, AxisRange(), AxisRange(catIdx, catIdx+1))\n",
    "\t\t\t// Embed it accordingly.\n",
    "\t\t\tembedCtx := ctx.In(fmt.Sprintf(\"categorical_%d_%s\", catIdx, adult.Data.VocabulariesFeatures[catIdx]))\n",
    "\t\t\tvocab := adult.Data.Vocabularies[catIdx]\n",
    "\t\t\tvocabSize := len(vocab)\n",
    "\t\t\tembedding := layers.Embedding(embedCtx, split, ModelDType, vocabSize, *flagEmbeddingDim)\n",
    "\t\t\tembedding.AssertDims(batchSize, *flagEmbeddingDim) // 2-dim tensor, with batch size as the leading dimension.\n",
    "\t\t\tallEmbeddings = append(allEmbeddings, embedding)\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tif *flagUseContinuous {\n",
    "\t\t// Piecewise-linear calibration of the continuous values. Each feature has its own number of quantiles.\n",
    "\t\tnumContinuous := continuous.Shape().Dimensions[1]\n",
    "\t\tfor contIdx := 0; contIdx < numContinuous; contIdx++ {\n",
    "\t\t\t// Take one column at a time of the continuous values.\n",
    "\t\t\tsplit := Slice(continuous, AxisRange(), AxisRange(contIdx, contIdx+1))\n",
    "\t\t\tfeatureName := adult.Data.QuantilesFeatures[contIdx]\n",
    "\t\t\tcalibrationCtx := ctx.In(fmt.Sprintf(\"continuous_%d_%s\", contIdx, featureName))\n",
    "\t\t\tquantiles := adult.Data.Quantiles[contIdx]\n",
    "\t\t\tlayers.AssertQuantilesForPWLCalibrationValid(quantiles)\n",
    "\t\t\tcalibrated := layers.PieceWiseLinearCalibration(calibrationCtx, split, Const(g, quantiles),\n",
    "\t\t\t\t*flagTrainableCalibration)\n",
    "\t\t\tcalibrated.AssertDims(batchSize, 1) // 2-dim tensor, with batch size as the leading dimension.\n",
    "\t\t\tallEmbeddings = append(allEmbeddings, calibrated)\n",
    "\t\t}\n",
    "\t}\n",
    "\tlogits := Concatenate(allEmbeddings, -1)\n",
    "\tlogits.AssertDims(batchSize, -1) // 2-dim tensor, with batch size as the leading dimension (-1 means it is not checked).\n",
    "\n",
    "\t// Model itself is an FNN or a KAN.\n",
    "\tif context.GetParamOr(ctx, \"kan\", false) {\n",
    "\t\t// Use KAN, all configured by context hyperparameters. See createDefaultContext for defaults.\n",
    "\t\tlogits = kan.New(ctx.In(\"kan\"), logits, 1).Done()\n",
    "\t} else {\n",
    "\t\t// Normal FNN, all configured by context hyperparameters. See createDefaultContext for defaults.\n",
    "\t\tlogits = fnn.New(ctx.In(\"fnn\"), logits, 1).Done()\n",
    "\t}\n",
    "\tlogits.AssertDims(batchSize, 1) // 2-dim tensor, with batch size as the leading dimension.\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "\n",
    "%%\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "\n",
    "// Let's just check that we get the right shape from the model function, wihtout any real data.\n",
    "ctx, _ := contextFromSettings()\n",
    "graph := NewGraph(backend, \"test\")\n",
    "batchSize := context.GetParamOr(ctx, \"batch_size\", 128)\n",
    "// Create placeholder (parameters) graph nodes, just to test the graph building is working.\n",
    "inputs := []*Node{\n",
    "    // Categorical: shaped [batch_size, num_categorical]\n",
    "    Parameter(graph, \"categorical\", shapes.Make(dtypes.Int64, batchSize, len(adult.Data.VocabulariesFeatures))),\n",
    "    // Continuous: shaped [batch_size, num_continuos]\n",
    "    Parameter(graph, \"continuous\", shapes.Make(dtypes.Float32, batchSize, len(adult.Data.QuantilesFeatures))),\n",
    "    // Weights: shaped [batch_size, 1]\n",
    "    Parameter(graph, \"weights\", shapes.Make(dtypes.Float32, batchSize, 1)),    \n",
    "}\n",
    "logits := ModelGraph(ctx, nil, inputs)\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", batchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1c7a-ced1-4914-8530-0924e02f095c",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "We can create a training loop with only a `Manager`, a `Context` (for the model varibles) and the `ModelGraph` function.\n",
    "\n",
    "To make it more interesting we also add the following:\n",
    "\n",
    "* Accuracy metrics for training and testing.\n",
    "* Checkpoints -- so trained model can be saved, and reloaded.\n",
    "* A progress-bar that also shows training metrics.\n",
    "* We dynamically plot how the loss and accuracy evolve.\n",
    "\n",
    "First we define the corresponding flags and the `trainModel` function, and run it for very few steps to make sure\n",
    "it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf39a7c-7cc8-43a5-ae79-026303f5f502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (2669 steps/s)\u001b[0m [step=99] [loss+=0.407] [~loss+=0.505] [~loss=0.504] [~acc=75.63%]                \n",
      "\t[Step 100] median train step: 293 microseconds\n",
      "Results on batched train:\n",
      "\tMean Loss+Regularization (#loss+): 0.437\n",
      "\tMean Loss (#loss): 0.436\n",
      "\tMean Accuracy (#acc): 79.59%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.433\n",
      "\tMean Loss (#loss): 0.433\n",
      "\tMean Accuracy (#acc): 79.77%\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"time\"\n",
    "    \"github.com/gomlx/gomlx/ui/gonb/plotly\"\n",
    "    \"github.com/gomlx/gomlx/pkg/support/fsutil\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    flagCheckpoint     = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    "    flagPlots          = flag.Bool(\"plots\", true, \"Plots during training: perform periodic evaluations, \"+\n",
    "                                   \"save results if --checkpoint is set and draw plots, if in a Jupyter notebook.\")\n",
    "    flagPlotType       = flag.String(\"plot_type\", \"plotly\", \"Type of plot to use, values are \\\"plotly\\\" or \\\"margaid\\\"\")\n",
    ")\n",
    "\n",
    "func trainModel(ctx *context.Context, paramsSet []string) {\n",
    "    *flagDataDir = must.M1(fsutil.ReplaceTildeInDir(*flagDataDir))\n",
    "\n",
    "    // Load data and create datasets.\n",
    "    adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "    trainDS, trainEvalDS, testEvalDS := BuildDatasets(ctx)\n",
    "\n",
    "\t// Checkpoints loading (and saving)\n",
    "\tvar checkpoint *checkpoints.Handler\n",
    "\tif *flagCheckpoint != \"\" {\n",
    "\t\tnumCheckpointsToKeep := context.GetParamOr(ctx, \"num_checkpoints\", 3)\n",
    "\t\tcheckpoint = must.M1(checkpoints.Build(ctx).\n",
    "\t\t\tDirFromBase(*flagCheckpoint, *flagDataDir).\n",
    "\t\t\tKeep(numCheckpointsToKeep).\n",
    "\t\t\tExcludeParams(append(paramsSet, \"train_steps\", \"plots\", \"num_checkpoints\")...).\n",
    "\t\t\tDone())\n",
    "\t}\n",
    "\n",
    "\t// Metrics we are interested.\n",
    "\tmeanAccuracyMetric := metrics.NewMeanBinaryLogitsAccuracy(\"Mean Accuracy\", \"#acc\")\n",
    "\tmovingAccuracyMetric := metrics.NewMovingAverageBinaryLogitsAccuracy(\"Moving Average Accuracy\", \"~acc\", 0.01)\n",
    "\n",
    "\t// Create a train.Trainer: this object will orchestrate running the model, feeding\n",
    "\t// results to the optimizer, evaluating the metrics, etc. (all happens in trainer.TrainStep)\n",
    "\ttrainer := train.NewTrainer(backend, ctx, ModelGraph, losses.BinaryCrossentropyLogits,\n",
    "\t\toptimizers.FromContext(ctx),\n",
    "\t\t[]metrics.Interface{movingAccuracyMetric}, // trainMetrics\n",
    "\t\t[]metrics.Interface{meanAccuracyMetric})   // evalMetrics\n",
    "\n",
    "    // Use standard training loop.\n",
    "    loop := train.NewLoop(trainer)\n",
    "    commandline.AttachProgressBar(loop) // Attaches a progress bar to the loop.\n",
    "\n",
    "    // Attach a checkpoint saver: checkpoint every 1 minute of training.\n",
    "    if checkpoint != nil {\n",
    "        period := time.Minute * 1\n",
    "        train.PeriodicCallback(loop, period, true, \"saving checkpoint\", 100,\n",
    "            func(loop *train.Loop, metrics []*tensors.Tensor) error {\n",
    "                fmt.Printf(\"\\n[saving checkpoint@%d] [median train step (ms): %d]\\n\", loop.LoopStep, loop.MedianTrainStepDuration().Milliseconds())\n",
    "                return checkpoint.Save()\n",
    "            })\n",
    "    }\n",
    "\n",
    "\t// Attach Plotly plots: plot points at exponential steps.\n",
    "\t// The points generated are saved along the checkpoint directory (if one is given).\n",
    "\tif context.GetParamOr(ctx, margaid.ParamPlots, false) {\n",
    "\t\t_ = plotly.New().\n",
    "\t\t\tWithCheckpoint(checkpoint).\n",
    "\t\t\tDynamic().\n",
    "\t\t\tWithDatasets(trainEvalDS, testEvalDS).\n",
    "\t\t\tScheduleExponential(loop, 200, 1.2)\n",
    "\t}\n",
    "\n",
    "\t// Train up to \"train_steps\".\n",
    "\tglobalStep := int(optimizers.GetGlobalStep(ctx))\n",
    "\ttrainSteps := context.GetParamOr(ctx, \"train_steps\", 0)\n",
    "\tif globalStep < trainSteps {\n",
    "\t\tif globalStep != 0 {\n",
    "\t\t\tfmt.Printf(\"\\t- restarting training from global_step=%d\\n\", globalStep)\n",
    "            trainer.SetContext(ctx.Reuse())\n",
    "\t\t}\n",
    "\t\t_ = must.M1(loop.RunSteps(trainDS, trainSteps-globalStep))\n",
    "\t\tfmt.Printf(\"\\t[Step %d] median train step: %d microseconds\\n\", loop.LoopStep, loop.MedianTrainStepDuration().Microseconds())\n",
    "\t} else {\n",
    "\t\tfmt.Printf(\"\\t - target train_steps=%d already reached. To train further, set a number larger than \"+\n",
    "\t\t\t\"current global step.\\n\", trainSteps)\n",
    "\t}\n",
    "\n",
    "\t// Finally, print an evaluation on train and test datasets.\n",
    "\tmust.M(commandline.ReportEval(trainer, trainEvalDS, testEvalDS))\n",
    "}\n",
    "\n",
    "// Notice command line flags are passed in the %% notebook command. We set plots=false here to disable plotting\n",
    "// since this is only a quick test that our train() loop is working. See below the final run for a full training.\n",
    "%% -set=\"train_steps=100;plots=false\"\n",
    "trainModel(contextFromSettings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5db6b-3a2c-4f48-8264-f90b22a52ed0",
   "metadata": {},
   "source": [
    "## Final run with 5K steps\n",
    "\n",
    "With everything working, we can do our final run.\n",
    "\n",
    "> **Note** here is where someone might want to hyperparameter tune, trying out different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d901d9-c503-4a94-8dec-a471a18bbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove previously trained model -- skip this cell, if you want to continue training.\n",
    "!rm -rf ~/work/uci-adult/base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66939463-60d7-446f-b4f3-1d60abe7c17c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m  14% [====>...................................] (148 steps/s) [1s:28s]\u001b[0m [step=724] [loss+=0.324] [~loss+=0.329] [~loss=0.329] [~acc=85.47%]        "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (1649 steps/s)\u001b[0m [step=4999] [loss+=0.194] [~loss+=0.275] [~loss=0.274] [~acc=87.12%]                \n",
      "\n",
      "[saving checkpoint@5000] [median train step (ms): 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"35f8e6bf\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.7672504186630249,0.8334478735923767,0.8555190563201904,0.8619110584259033,0.8697666525840759,0.8706505298614502,0.8720096945762634,0.8716121315956116,0.8757058382034302,0.8711881637573242]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.8217806816101074,0.8514173626899719,0.8599244356155396,0.8693221807479858,0.8713799118995667,0.8712570667266846,0.8738061189651489,0.8741438984870911,0.8747581839561462,0.8742053508758545]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.8250107169151306,0.8505005240440369,0.8587309718132019,0.8666543364524841,0.868558406829834,0.8700324892997742,0.8715065717697144,0.8713223338127136,0.871383786201477,0.872489333152771]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('35f8e6bf', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"21d5739b\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.3992919325828552,0.3745863735675812,0.2706328332424164,0.3600202202796936,0.2264464795589447,0.28429168462753296,0.28600525856018066,0.3500482738018036,0.26034075021743774,0.19376729428768158]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.49557584524154663,0.37819311022758484,0.3280414640903473,0.3022926151752472,0.2879444658756256,0.2836146652698517,0.27676987648010254,0.27780649065971375,0.2688152492046356,0.27462640404701233]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.49513328075408936,0.37772703170776367,0.3275585174560547,0.301797479391098,0.28743934631347656,0.28309744596481323,0.27624139189720154,0.2772669494152069,0.2682636082172394,0.27406445145606995]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.421759694814682,0.34560176730155945,0.31224536895751953,0.2919577956199646,0.28422051668167114,0.2792373299598694,0.2749784588813782,0.272156685590744,0.27078118920326233,0.2706703543663025]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.4213055670261383,0.34512805938720703,0.3117579221725464,0.2914595305919647,0.28371262550354004,0.27871784567832947,0.27444788813591003,0.2716149687767029,0.2702277898788452,0.2701072096824646]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.4189731776714325,0.34400635957717896,0.3153647184371948,0.2967787981033325,0.29148414731025696,0.2868884801864624,0.2828328013420105,0.2810054421424866,0.2809080481529236,0.2796786427497864]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.4185190796852112,0.3435327410697937,0.3148772120475769,0.29628050327301025,0.29097628593444824,0.2863689661026001,0.28230223059654236,0.28046372532844543,0.2803546190261841,0.2791154384613037]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('21d5739b', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 5000] median train step: 263 microseconds\n",
      "Results on batched train:\n",
      "\tMean Loss+Regularization (#loss+): 0.271\n",
      "\tMean Loss (#loss): 0.27\n",
      "\tMean Accuracy (#acc): 87.42%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.28\n",
      "\tMean Loss (#loss): 0.279\n",
      "\tMean Accuracy (#acc): 87.25%\n"
     ]
    }
   ],
   "source": [
    "%% --checkpoint base_model -set=\"plots=true;train_steps=5000\"\n",
    "trainModel(contextFromSettings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d8a41-3e9c-4107-a507-c879ef27e3e3",
   "metadata": {},
   "source": [
    "## Extend training another 5K steps\n",
    "\n",
    "Since the model training went well, and it doesn't seem to be yet terribly overfiting, \n",
    "let's train further, another 5k steps, for 10K steps in total.\n",
    "\n",
    "Notice the plots continue from where it stopped. And this time we use [Plotly](https://plotly.com/javascript/) to plot the training results -- they don't display in Github since they depend on javascript.\n",
    "\n",
    "Unfortunately, it doesn't help (the accuracy on the test set doesn't improve), 5k steps was already enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95983f61-2a98-442d-bc5d-896006289a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps=10000\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- restarting training from global_step=5000\n",
      "      \u001b[1m 100% [========================================] (1656 steps/s)\u001b[0m [step=9999] [loss+=0.301] [~loss+=0.268] [~loss=0.267] [~acc=87.45%]                 \n",
      "\n",
      "[saving checkpoint@10000] [median train step (ms): 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"c8b3fe6f\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.7672504186630249,0.8334478735923767,0.8555190563201904,0.8619110584259033,0.8697666525840759,0.8706505298614502,0.8720096945762634,0.8716121315956116,0.8757058382034302,0.8711881637573242,0.8746286034584045,0.8749567866325378,0.8737866878509521,0.8714452981948853,0.8744620084762573]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.8217806816101074,0.8514173626899719,0.8599244356155396,0.8693221807479858,0.8713799118995667,0.8712570667266846,0.8738061189651489,0.8741438984870911,0.8747581839561462,0.8742053508758545,0.8742360472679138,0.8750959634780884,0.8730690479278564,0.8749731183052063,0.8746353387832642]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.8250107169151306,0.8505005240440369,0.8587309718132019,0.8666543364524841,0.868558406829834,0.8700324892997742,0.8715065717697144,0.8713223338127136,0.871383786201477,0.872489333152771,0.871936559677124,0.871383786201477,0.8705238699913025,0.8707081079483032,0.8710152506828308]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('c8b3fe6f', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"fbbf488c\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.3992919325828552,0.3745863735675812,0.2706328332424164,0.3600202202796936,0.2264464795589447,0.28429168462753296,0.28600525856018066,0.3500482738018036,0.26034075021743774,0.19376729428768158,0.2971706986427307,0.2033868134021759,0.20468772947788239,0.2443217784166336,0.3005202114582062]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.49557584524154663,0.37819311022758484,0.3280414640903473,0.3022926151752472,0.2879444658756256,0.2836146652698517,0.27676987648010254,0.27780649065971375,0.2688152492046356,0.27462640404701233,0.27095210552215576,0.2706863582134247,0.26939642429351807,0.27220770716667175,0.2678545117378235]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.49513328075408936,0.37772703170776367,0.3275585174560547,0.301797479391098,0.28743934631347656,0.28309744596481323,0.27624139189720154,0.2772669494152069,0.2682636082172394,0.27406445145606995,0.2703873813152313,0.27010783553123474,0.2688036859035492,0.2715997099876404,0.2672431170940399]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.421759694814682,0.34560176730155945,0.31224536895751953,0.2919577956199646,0.28422051668167114,0.2792373299598694,0.2749784588813782,0.272156685590744,0.27078118920326233,0.2706703543663025,0.2701721787452698,0.2696975767612457,0.27071207761764526,0.268804132938385,0.2682928740978241]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.4213055670261383,0.34512805938720703,0.3117579221725464,0.2914595305919647,0.28371262550354004,0.27871784567832947,0.27444788813591003,0.2716149687767029,0.2702277898788452,0.2701072096824646,0.2696065902709961,0.2691185176372528,0.27011793851852417,0.2681948244571686,0.26767903566360474]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.4189731776714325,0.34400635957717896,0.3153647184371948,0.2967787981033325,0.29148414731025696,0.2868884801864624,0.2828328013420105,0.2810054421424866,0.2809080481529236,0.2796786427497864,0.27958351373672485,0.2803860008716583,0.28248003125190735,0.2806776463985443,0.2818298637866974]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000,5200,6441,7930,9717,10000],\"y\":[0.4185190796852112,0.3435327410697937,0.3148772120475769,0.29628050327301025,0.29097628593444824,0.2863689661026001,0.28230223059654236,0.28046372532844543,0.2803546190261841,0.2791154384613037,0.27901792526245117,0.2798070013523102,0.28188586235046387,0.28006836771965027,0.2812160551548004]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('fbbf488c', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 264 microseconds\n",
      "Results on batched train:\n",
      "\tMean Loss+Regularization (#loss+): 0.268\n",
      "\tMean Loss (#loss): 0.268\n",
      "\tMean Accuracy (#acc): 87.46%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.282\n",
      "\tMean Loss (#loss): 0.281\n",
      "\tMean Accuracy (#acc): 87.10%\n"
     ]
    }
   ],
   "source": [
    "%% --checkpoint base_model -set=\"plots=true;train_steps=10000\"\n",
    "ctx, paramsSet := contextFromSettings()\n",
    "fmt.Printf(\"train_steps=%d\\n\", context.GetParamOr(ctx, \"train_steps\", 0))\n",
    "trainModel(ctx, paramsSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06427d06-00d5-4ee5-a408-ddb58621317f",
   "metadata": {},
   "source": [
    "## Using Kolmogorov-Arnold Networks (KAN)\n",
    "\n",
    "Since it's avaialable as a layer (see package `kan`), the model supports it by simply changing a hyperparameter.\n",
    "\n",
    "See description in https://arxiv.org/pdf/2404.19756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5d50910-c351-4dda-98cb-5abae8a11ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove previously trained model -- skip this cell, if you want to continue training.\n",
    "!rm -rf ~/work/uci-adult/kan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce56c29-0678-4a4f-a028-7a86de57e915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m   7% [=>......................................] (127 steps/s) [1s:1m12s]\u001b[0m [step=719] [loss+=4.2] [~loss+=4.28] [~loss=0.405] [~acc=81.99%]         "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (1766 steps/s)\u001b[0m [step=9999] [loss+=1.17] [~loss+=1.21] [~loss=0.291] [~acc=86.79%]                  \n",
      "\n",
      "[saving checkpoint@10000] [median train step (ms): 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"132b0906\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.7176172137260437,0.7960608601570129,0.8197047710418701,0.8251006007194519,0.838468611240387,0.8363748788833618,0.8393341898918152,0.8426470160484314,0.8474530577659607,0.8549295663833618,0.859634518623352,0.8635213971138,0.8649033308029175,0.8679285049438477]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.7854795455932617,0.8094345927238464,0.8250361084938049,0.8309327363967896,0.8377506732940674,0.8379963636398315,0.8415282368659973,0.8429102301597595,0.852092981338501,0.8546727895736694,0.860907256603241,0.8649611473083496,0.865483283996582,0.8666502833366394]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.7874208688735962,0.8135863542556763,0.822001039981842,0.8271604180335999,0.835513710975647,0.8341010212898254,0.8409802317619324,0.8433756232261658,0.8495792150497437,0.8508076071739197,0.8560284376144409,0.8551071286201477,0.8602050542831421,0.8605735898017883]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('132b0906', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"65767452\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[4.676569938659668,4.4158148765563965,4.26179838180542,3.9953525066375732,3.7703969478607178,3.580827474594116,3.3363990783691406,2.953735589981079,2.591047763824463,2.2510828971862793,1.929321050643921,1.5275228023529053,1.1808305978775024,1.173614740371704]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[4.729458808898926,4.485419273376465,4.275432109832764,4.063136577606201,3.8176002502441406,3.568863868713379,3.2853193283081055,2.9722299575805664,2.636160135269165,2.2793021202087402,1.9201117753982544,1.5721112489700317,1.2488068342208862,1.205512523651123]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5629305243492126,0.450712651014328,0.4052780568599701,0.3846519887447357,0.3583480417728424,0.35692161321640015,0.34902969002723694,0.3386872112751007,0.3293199837207794,0.3163074254989624,0.30735304951667786,0.30098244547843933,0.29268941283226013,0.29130345582962036]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[4.6085309982299805,4.406857967376709,4.209271430969238,3.9994993209838867,3.765171527862549,3.515686511993408,3.2346737384796143,2.933844566345215,2.59513521194458,2.2490334510803223,1.8917492628097534,1.5469890832901,1.2296416759490967,1.1880782842636108]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on batched train\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.49071887135505676,0.4296126961708069,0.39559483528137207,0.3752969205379486,0.3572711646556854,0.3517640233039856,0.34263280034065247,0.3404400050640106,0.32399097084999084,0.3169403672218323,0.3047012984752655,0.29618290066719055,0.2886831760406494,0.2883373200893402]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[4.605977535247803,4.404934883117676,4.207498073577881,4.003383159637451,3.7689075469970703,3.5211706161499023,3.2379047870635986,2.9351277351379395,2.6041696071624756,2.2592837810516357,1.9038233757019043,1.5606415271759033,1.2411457300186157,1.200244426727295]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.4881667494773865,0.427689790725708,0.39382272958755493,0.3791819214820862,0.3610081672668457,0.3572480082511902,0.3458639085292816,0.3417232632637024,0.33302587270736694,0.3271908760070801,0.3167756497859955,0.3098354637622833,0.30018725991249084,0.30050358176231384]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('65767452', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 331 microseconds\n",
      "Results on batched train:\n",
      "\tMean Loss+Regularization (#loss+): 1.19\n",
      "\tMean Loss (#loss): 0.288\n",
      "\tMean Accuracy (#acc): 86.67%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 1.2\n",
      "\tMean Loss (#loss): 0.301\n",
      "\tMean Accuracy (#acc): 86.06%\n"
     ]
    }
   ],
   "source": [
    "%% --checkpoint kan_model -set=\"kan=true;activation=swish;plots=true;train_steps=10_000\"\n",
    "trainModel(contextFromSettings())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "text/x-go",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.24.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
