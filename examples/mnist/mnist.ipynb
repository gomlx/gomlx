{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "MNIST is a simple computer vision dataset that consists of images of handwritten digits.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "![MNIST digits sample](https://github.com/user-attachments/assets/996c11e0-47f9-4b21-8e23-3867b8942e64)\n",
    "\n",
    "It also includes labels for each image, which we use to train our example models.\n",
    "\n",
    "## The `mnist` library\n",
    "\n",
    "This package includes the following functionality:\n",
    "\n",
    "  - Download the dataset from [storage.googleapis.com/cvdf-datasets/mnist](https://storage.googleapis.com/cvdf-datasets/mnist),\n",
    "  - Create a `Dataset` object to iterate over it, use for training and evaluation.\n",
    "  - A linear and a CNN model demo.\n",
    "  - A command-line demo (in the `demo` sub-directory).\n",
    "\n",
    "This notebook serves as documentation and example for the [github.com/gomlx/gomlx/examples/mnist](https://github.com/gomlx/gomlx/examples/mnist) library, and the demo code in one piece can be seen in [.../examples/mnist/demo/](https://github.com/gomlx/gomlx/tree/main/examples/mnist/demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n"
     ]
    }
   ],
   "source": [
    "!*rm -f go.work && go work init && go work use . \"${HOME}/Projects/gomlx\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Downloading data files\n",
    "\n",
    "To download to the local directory, simply do the following. Notice if it's already downloaded in the given `--data` directory, it returns immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/pkg/support/fsutil\"\n",
    "    \"github.com/janpfeifer/must\"\n",
    ")\n",
    "\n",
    "var flagDataDir = flag.String(\"data\", \"~/work/mnist\", \"Directory to cache downloaded and generated dataset files.\")\n",
    "\n",
    "func AssertDownloaded() {\n",
    "    *flagDataDir = must.M1(fsutil.ReplaceTildeInDir(*flagDataDir))\n",
    "    if !fsutil.MustFileExists(*flagDataDir) {\n",
    "        must.M(os.MkdirAll(*flagDataDir, 0777))\n",
    "    }\n",
    "   must.M(mnist.Download(*flagDataDir))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12M\n",
      "drwxr-x--- 2 janpf janpf 4.0K Jun  3 15:39 cnn_triplet\n",
      "drwxr-x--- 2 janpf janpf 4.0K Jun  3 15:38 linear\n",
      "drwxr-x--- 2 janpf janpf 4.0K Feb 13  2025 linear_baseline\n",
      "-rw-r--r-- 1 janpf janpf 1.6M Jun  8 08:10 t10k-images-idx3-ubyte.gz\n",
      "-rw-r--r-- 1 janpf janpf 4.5K Jun  8 08:11 t10k-labels-idx1-ubyte.gz\n",
      "-rw-r--r-- 1 janpf janpf 9.5M Jun  8 08:09 train-images-idx3-ubyte.gz\n",
      "-rw-r--r-- 1 janpf janpf  29K Jun  8 08:09 train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/work/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample some images\n",
    "The `mnist.NewDataset` creates a `data.InMemoryDataset` that can be used both for training, evaluation, or just to sample a few examples, which we do below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Samples MNIST</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA3ElEQVR4nOyVXa6EIAyF5ebui7qylpUVVuYkNjkhjJKqkPgw3xNp8NCfA/4tE3iBqIhsO6o64HAiUtWtorP5369o6xCCiDzNESVDi3buKxLRyCYa4xVtMiMV0cpH7WuYVXjfjJcZnyZsdFvh4EbZZFJKnVNtT4yxlOK6YDb3761EBEs0NA7xvlIioqrMjEhKKedcFwdOH5QYI9aqap/lnNd1reMWhPopGJTNCvZCOk0fnLUuzdNp9rIONMFr963O95DO0ENfl5lLKcwMh7k6OIMX/E1/oh4+AQAA//88BhWRyqTRXQAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([6])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACEElEQVR4nOyVO4vqThjGJxeyu2z20iysBi0EBQUJaCGpxEYklaW9toJaeAvWIlgLyTewEQvFD2BpYadgIQQFqxRiLCIz8Q+bP56QE0eLY3HgPN288/ibh/F9JyR4gP5BHwytVCrlctnj8eB/4/P5EELJZPKuExBCEMLRaIS3KYoCIdzv99/f37eTqqoKAPj4+MAQo9FoNpsFALAsS1HUbWi73UYI4WMyDPP8/Iz3OKWq6maz4Xke4+n3+xBChBDHcbeTAgAIgvB6vcFgEH82QRAkebVznBvnH7VaLTz0fD6bpnkv1NL7+7trPR6P53K5VCplLYvFoquNdq/S9Nvb2+FwuFQ+Pz9lWRZF8eXl5VIMh8NPT0+GYVyL/L9UVYU/KpVKduJsNrO6+CJrmUgkfoe4/FGWLhVBEDRNi8ViJEkSBNHpdPL5/Hw+t5Z251UVCgV7UkmSdrudVVkul5FIhGEYAEC328WMnzPper22rtLv99frdUmSvr6+DMNoNpuZTGaxWJxOJ7sfP36/NB6P7bd2PB4bjYbDw/O8tTudTu+CCoJgh1arVVfbYDC4BnV5EWiafn191XV9OBwqitLr9VyhHMel02nTNCeTiaZpt8NSFMWyLN7Dsux2u4UQrlarUChk33KfKISQrut4qK7r1pMWCAREUbwNvVOyLDua4c+oVqs5xu9R+ns+0f8FAAD//9GOCektOvKwAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([4])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABmUlEQVR4nOzVTat5QRzA8dO/f1Ia5SmZZusF2IuSBW+C7JSVsmFjpewtZCULSzZW56RYIDan2Ngf2Y4UIb+TW+aa7pOuM+Nubve7Ypo+89NM+af8QH/oN7VaLfPaYDAoFosIIdkz0+n04XCAa6ZpAsBwOEwmk+JiKBTa7XZwi6EAMJvNvF6vIBoMBlerFUeXy6Wu6+yzpmk+n0/QjcfjAHA8HlVVJYT4/f7RaMTcWCwmiDocjmq1GolE+EqpVGJoKpUSRD9nGAZDJ5PJvT0W3ilCqNFouFwu9rXT6cgOaLfbx+MxvzRd1wkhsmilUuFPaj6fBwIBWZF1uVzMW4VC4TlouVzmP/90OkWj0SegCCGM8Xq9Zq6qqvd2/n8cxRhnMhmPx8PPsIy63e5arTadTgkhmqYpitJsNjHGfEO9Xn98oNfa7Ta8j98+AHS7Xf5gLUzqdDq/XN9ut/1+P5vNbjYby5OGw+H9fv9hUsMwEomEZettvV6PcefzmVKay+VsNpuUyK57sVhQSvP5vKwl32/6ixboJQAA//+bKB36+9lwuwAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([3])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABuUlEQVR4nOyVMYviUBRGH0tUUNRgISja28XCgJ2VtiJYWNsqNtYiVv4AY2XhPxAsBIkBewU7MSAiBH3aiPAMBsTcuzAyQ5rdjdksTLGnPLwcvurmB/kH/I9+p2gqlTqfz4qiuBnt9/vRaPR0Ojn5mOd5SZJisZhVCoJgmub9fk8kEk6is9kMAKrVqlXO53NErNVqTortdts0TU3TeJ63bqeU6rruZGY2m9V1nTFWKBSsfjAYAEC9Xn+7GA6HKaUA0O12rT4SiVBKGWPJZPLt6HA4RERFUUKhkNW3Wi1ElGWZ4zhRFBuNht2iKIqGYQBAPp/3er1f3ufzrddrAJhMJvv9HgCm06nd6PF4hE92u536wXK5XK1WX/5yuTSbzUAgYKtYqVSezycAbLfbzWbzWmRFluVcLhePx+1uJIQYhoGIkiRxHEcI8fv9wgfFYhERH49HOp1+I/ei0+n0er1X0YokSQAwGo3eLv4Kj8ejqioiZjIZ16KlUgkADodDMBj842O7V6pcLhNCxuPx7Xb764WfqKoKAIIg2Hn8xj1ljF2vV5eji8VC0zSXo04uiIt8s7/pb/gZAAD//72a8t/coIzAAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([4])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABmElEQVR4nOyVr4sCQRTHZ70ZxS1evE2CSRGtgkUsCiZBYYMgWBQM/gOmAUEwidlmMCpssqxr9hcIRpO4YhAviIsMzBwoHsLh6bhrOe5T573PfHkzw9jAC/iX/gFpsVhkjPV6PZvNor1FURwMBt1ul1JaKpW4vG+3FjDG2+02n88jhCqVisPhGI1GjLFAIPBxwjCM4/HIl1RRFFEUAQB2uz2Xy81ms81ms1wu6YVkMsln/AlC6P1Cp9PBGCOEzEq/KRQKhJBoNPpLDfexejyearXa7/fNZbvC7Xbruh6Pxy0zOp1OTdPa7TaE0JQoFovV6/XzNchkMvv9PhKJmE2HMTYMQ1XVYDA4Ho9rtdojXcLdClmWW60WhFAQhHK5vFgsJElKJBK73U6W5efzZrNZSiljjFKq6/pkMmk2m6FQ6Fb9QyM/HA4AgHA4vF6vP088H/CMy+UaDoeKopgVXZNKpQghXq/XMiOEcD6fq6rK1XXnmfr9fp/Pp2maldJ0Or1arXgHekcqSVKj0ZhOp1zSl/CS3/QrAAD//43jpLt0T4riAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([7])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABk0lEQVR4nOTVPYvCMBgH8Nxx+DL0MzhZcBBH6WJ1UaTSwUFwE/QD1K/gIC5+Adfi0E3BzdFd3BwEQbIJYnTo1Ke5IVwIXgj0xeG4/6RP4i/BPGk/0Rvyz9Ev9bCu65ZlIYRs267X62EYsvp6ve52u3EW1HX9dDoFPwGAQEiv18vn85HR8/ksKi8oAMxmM+kPVf/pZrMBAIQQAGCMl8vldDrFGPu+zyaUSqVsNht5s6PRyHGc4XAoFj3P4xuvVquRUWk8zwMASunxeCwUCr8nxGwpSmkYhofD4XK5pIB2Op1GoxFvK/IYhnG9XtnpE0JarVYKqOu6vKVM00xBXK1WICQpZxiG67q8+Z/PZ7/fTyRqmrbdbnlj3u/3wWCQSGy320zk6G63SySapkkIebn7GONKpRKH0zRtPB5TSsWTEb86jhMZXSwW0scS/3y73aKJ5XKZdbgCDYJAIUiuaSaTyeVy6oUJIYrRD2nVsqxisTifzyeTyePxYMVarWbbNhObzeZ+v1cvnHL+ziv6Leh3AAAA///LemKazxJP/wAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABrklEQVR4nOzVv2rCQBwH8CTUDBIPXaIkuyCC4uATdHBydnCSZHFz8RHEZxAUFHQUFcFBD1/AgBACQgb/4GQwS0RU8M5SQ4ND2rQ1dih+tySXT345vnAU8YA80T9HK5WKfE0+n3ftm5qmoY8sl0tRFH0+371oLBar1+uGYVj0bDbL5XIuzBuNRguFguUeDgdBEFxwSZKMRCKtVut8PmOMR6ORC6gZAMB6vXZEf1ApAECxWOQ4jiTJ+Xzuwowej6dcLpt72uv1vF7vvSLP8xBCfM1qtUokEndxNE1ns1ld180ZJUkKhUK2KxmGeb3GGa3ValaT2u02wzC3T5PJpCiKw+FQlmVVVRFCjUbjK87v91vidrtNp9MAgEAgEAwGS6WSLMu73e50OpkLNpuNoiiZTIam6ff+2YqpVKparXIcZ15CCHVdD4fDPM+zLEtRFMaYIIjJZDIYDFRV7Xa7x+PRet0exRhfLpfPfmI6nUIIO52OJEkIIYcdvEXRTfb7vWEYi8VCEASWZR379GJ7t9lsxuNxRVHG4zFBEP1+X9O07070oPyb4+SJ/iJvAQAA//97Rf6gJPo1kwAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAu0lEQVR4nNyVYQrDIAyF113M5GTGk715sg6aEWSjmmkGo+9XC/bLa0ie99sPdGGoiOyHYuobTiUiq0QAhtPnAJtGJCJ1vUokojdovM2hNif0dXpznR+PlLWPmT3EsdpuAnB+NXDaNlELeNDejXocMnQMtNbKzKUUfe1Pwne7LyLMrJZzzpMzexYf/fUfOE0pzXjp69NRm1Uzv29DqtCw6NtPtJRSbYyGZTMRKRdAAG5F/3GbXgv6DAAA//+LoOTwb/4TZwAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([6])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABoUlEQVR4nOyVsYryQBDH5/MTXLGRPIIKFltYiJWVCPoIsbAKWFmZMr6EjYV2NiKWdhYWNmIRLGIhgqQSNYqIhVGE2RxHODkENbfJHRzcv8qSmd/+CMPEB9+QP+iPQwkh1WrVNE3GWLvdppSGQiG3d1JK8VMYY5PJJBwOu4KKooiI2+02kUh0u13TNBFxt9sVi0W/388JlWUZEVutln3MZrPT6dS2rlQqj7pefNNIJAIAuq7bx8FgkE6ny+XyarXq9/ucpvV6nTFmGMaXul6YWh/xEno+n9+LfD5CiHPov+evKaWapgHAeDxeLpeHw6HT6YxGo+v16vyO+wQCAUVRTqfTbU4RcTab5fN5flM7wWBQkiQAEARBFMV4PG4YRiqVWq/X/L53aTQaiKgoyqMCnoViCw6HQy+huVwOAAqFgpfQaDTK0fUwhBBZli3Lms/ngiC4YsViMfvhtgmbzeaTekfrq9frqaqq63omkwGA/X5fq9VcaQJAqVS6Df9ms0kmk8/r/zuBapp2PB4Xi8XlcpEkSVVVt5oc+T2/6LcAAAD//4960xatyqK0AAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([5])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABdElEQVR4nOzULasyQRQH8H12xJdiEjSLQaeNBq0WEcEmmCwGDYLRb2Aw+AUEbRYx6CSdaFaQCaJYbE6YIoiCo7MPl4VluXjZu3vXcPH+45xzfuwJe1TlBflD3xn1OJ4EAESjUfPLfr93AkEIEUKFQmEwGGw2G2nKeDw22v59x4pEIvl8vlQq5XI5j+djue12O51OD4fDfD7Xezjn5/PZxgdWq1UppaZpUkrOeaPR8Pl8ttc0oqpqp9O53W5SysfjMRwOE4mEc05PMpm83++TyaRYLMbj8Z9yerLZrBAilUq5wxkZjUZCiHa7HQgEXEODwWCtVjudTpTSdDrtmqsoSiaTwRgzxiCEbrp+v3+32/V6PduTXq8XAPBVtdlsHo/HWCxmD2WMLRaLp2MIofV63e/3LZHPB6XVanW7XUrpcrkkhFwuF6NUqVTC4TAhxBJ98u+HQqF6vV4ul82P1+t1NpthjFerlSX6kvyey//m6P8AAAD//5kuk0pEA9rDAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([5])</figcaption></figure></td>\n",
       "</tr></table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"strings\"\n",
    "\t\"strconv\"\n",
    "    \"github.com/gomlx/gopjrt/dtypes\"\n",
    "    \"github.com/gomlx/gomlx/backends\"\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/pkg/core/shapes\"\n",
    "    \"github.com/gomlx/gomlx/pkg/core/tensors/images\"\n",
    "    \"github.com/janpfeifer/gonb/gonbui\"\n",
    "\n",
    "    _ \"github.com/gomlx/gomlx/backends/default\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    // Model DType, used everywhere.\n",
    "    DType = dtypes.Float32\n",
    ")\n",
    "\n",
    "// sampleToNotebook generates a sample of MNIST in a GoNB Jupyter Notebook.\n",
    "func sampleToNotebook() {\n",
    "    // Load data into tensors.\n",
    "    backend := backends.MustNew()\n",
    "    if ds, err := mnist.NewDataset(backend, \"Samples MNIST\", *flagDataDir, \"train\", DType); err != nil {\n",
    "        fmt.Printf(\"mnist.NewDataset: %v\", err)\n",
    "    } else {\n",
    "        ds.Shuffle()\n",
    "        sampleImages(ds, 10)\n",
    "    }\n",
    "   \n",
    "}\n",
    "\n",
    "// sampleTable generates and outputs one html table of samples, sampling rows x cols from the images/labels provided.\n",
    "func sampleImages(ds train.Dataset, numImages int) {\n",
    "    gonbui.DisplayHTML(fmt.Sprintf(\"<p>%s</p>\\n\", ds.Name()))\n",
    "    \n",
    "    parts := make([]string, 0, numImages+5) // Leave last part empty.\n",
    "    parts = append(parts, \"<table><tr>\")\n",
    "    for ii := 0; ii < numImages; ii++ {\n",
    "        _, inputs, labels := must.M3(ds.Yield())\n",
    "        imgTensor := inputs[0]\n",
    "        img := images.ToImage().Single(imgTensor)\n",
    "        label := labels[0].Value().([]int8)\n",
    "    \n",
    "        imgSrc := must.M1(gonbui.EmbedImageAsPNGSrc(img))\n",
    "        size := imgTensor.Shape().Dimensions[0]\n",
    "        parts = append(\n",
    "            parts, \n",
    "            fmt.Sprintf(`<td><figure style=\"padding:4px;text-align: center;\"><img width=\"%d\" height=\"%d\" src=\"%s\">` + \n",
    "                        `<figcaption style=\"text-align: center;\">(%d)</figcaption></figure></td>`, \n",
    "                        size*2, size*2, imgSrc, label),\n",
    "        )\n",
    "    }\n",
    "    parts = append(parts, \"</tr></table>\", \"\")\n",
    "    gonbui.DisplayHTML(strings.Join(parts, \"\\n\"))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()\n",
    "sampleToNotebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on MNIST\n",
    "\n",
    "### Models Support\n",
    "\n",
    "1. `flagModel` defines the model type, out of `validModels` options.\n",
    "1. `createDefaultContext` creates a context and set the default values for the MNIST models. \n",
    "1. `contextFromSettings` uses `createDefaultContext` and incorporate changes passed by the `-set` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: [\"linear\" \"cnn\"]\n",
      "Parameters set (-set): [\"batch_size\" \"model\" \"train_steps\"]\n",
      "\t\"/activation\": (string) relu\n",
      "\t\"/adam_dtype\": (string) \n",
      "\t\"/adam_epsilon\": (float64) 1e-07\n",
      "\t\"/batch_size\": (int) 17\n",
      "\t\"/cnn_dropout_rate\": (float64) 0.5\n",
      "\t\"/cnn_normalization\": (string) layer\n",
      "\t\"/cosine_schedule_steps\": (int) 0\n",
      "\t\"/dropout_rate\": (float64) 0.5\n",
      "\t\"/eval_batch_size\": (int) 1000\n",
      "\t\"/l1_regularization\": (float64) 0\n",
      "\t\"/l2_regularization\": (float64) 0\n",
      "\t\"/learning_rate\": (float64) 0.0001\n",
      "\t\"/loss\": (string) sparse_cross_logits\n",
      "\t\"/model\": (string) 'cnn'\n",
      "\t\"/nan_logger\": (bool) false\n",
      "\t\"/num_checkpoints\": (int) 3\n",
      "\t\"/optimizer\": (string) adamw\n",
      "\t\"/plots\": (bool) false\n",
      "\t\"/train_steps\": (int) 10\n",
      "\t\"/triplet_loss_margin\": (float64) 0.5\n",
      "\t\"/triplet_loss_mining_strategy\": (string) Hard\n",
      "\t\"/triplet_loss_pairwise_distance_metric\": (string) L2\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flags\"\n",
    "    \n",
    "    \"github.com/gomlx/gomlx/pkg/ml/layers\"\n",
    "    \"github.com/gomlx/gomlx/ui/commandline\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/train/optimizers\"\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/context\"\n",
    ")\n",
    "\n",
    "var (\n",
    "\tflagEval      = flag.Bool(\"eval\", true, \"Whether to evaluate the model on the validation data in the end.\")\n",
    ")\n",
    "\n",
    "// settings is bound to a \"-set\" flag to be used to set context hyperparameters.\n",
    "var settings = commandline.CreateContextSettingsFlag(CreateDefaultContext(), \"set\")\n",
    "\n",
    "// createDefaultContext sets the context with default hyperparameters\n",
    "func CreateDefaultContext() *context.Context {\n",
    "\tctx := context.New()\n",
    "\tctx.RngStateReset()\n",
    "\tctx.SetParams(map[string]any{\n",
    "\t\t// Model type to use\n",
    "\t\t\"model\":           \"linear\",\n",
    "\t\t\"loss\":            \"sparse_cross_logits\",\n",
    "\t\t\"num_checkpoints\": 3,\n",
    "\t\t\"train_steps\":     4000,\n",
    "\n",
    "\t\t// batch_size for training.\n",
    "\t\t\"batch_size\": 600,\n",
    "\n",
    "\t\t// eval_batch_size can be larger than training, it's more efficient.\n",
    "\t\t\"eval_batch_size\": 1000,\n",
    "\n",
    "\t\t// Debug parameters.\n",
    "\t\t\"nan_logger\": false, // Trigger nan error as soon as it happens -- expensive, but helps debugging.\n",
    "\n",
    "\t\t// \"plots\" trigger generating intermediary eval data for plotting, and if running in GoNB, to actually\n",
    "\t\t// draw the plot with Plotly.\n",
    "\t\t//\n",
    "\t\t// From the command-line, an easy way to monitor the metrics being generated during the training of a model\n",
    "\t\t// is using the gomlx_checkpoints tool:\n",
    "\t\t//\n",
    "\t\t//\t$ gomlx_checkpoints --metrics --metrics_labels --metrics_types=accuracy  --metrics_names='E(Tra)/#loss,E(Val)/#loss' --loop=3s \"<checkpoint_path>\"\n",
    "\t\tplotly.ParamPlots: false,\n",
    "\n",
    "\t\toptimizers.ParamOptimizer:       \"adamw\",\n",
    "\t\toptimizers.ParamLearningRate:    1e-4,\n",
    "\t\toptimizers.ParamAdamEpsilon:     1e-7,\n",
    "\t\toptimizers.ParamAdamDType:       \"\",\n",
    "\t\tcosineschedule.ParamPeriodSteps: 0,\n",
    "\t\tactivations.ParamActivation:     \"relu\",\n",
    "\t\tlayers.ParamDropoutRate:         0.5,\n",
    "\t\tregularizers.ParamL2:            0.0,\n",
    "\t\tregularizers.ParamL1:            0.0,\n",
    "\n",
    "\t\t// CNN\n",
    "\t\t\"cnn_dropout_rate\":  0.5,\n",
    "\t\t\"cnn_normalization\": \"layer\", // \"layer\" or \"batch\".\n",
    "\n",
    "\t\t// Triplet\n",
    "\t\tlosses.ParamTripletLossPairwiseDistanceMetric: \"L2\",\n",
    "\t\tlosses.ParamTripletLossMiningStrategy:         \"Hard\",\n",
    "\t\tlosses.ParamTripletLossMargin:                 0.5,\n",
    "\t})\n",
    "\treturn ctx\n",
    "}\n",
    "\n",
    "// ContextFromSettings is the default context (createDefaultContext) changed by -set flag.\n",
    "func ContextFromSettings() (ctx *context.Context, paramsSet []string) {\n",
    "    ctx = mnist.CreateDefaultContext()\n",
    "    paramsSet = must.M1(commandline.ParseContextSettings(ctx, *settings))\n",
    "    return\n",
    "}\n",
    "\n",
    "// Let's test that we can set hyperparameters by setting it in the \"-set\" flag:\n",
    "%% -set=\"batch_size=17;model='cnn';train_steps=10\"\n",
    "fmt.Printf(\"Models: %q\\n\", mnist.ModelList)\n",
    "ctx, parametersSet := ContextFromSettings()\n",
    "fmt.Printf(\"Parameters set (-set): %q\\n\", parametersSet)\n",
    "fmt.Println(commandline.SprintContextSettings(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model\n",
    "\n",
    "A linear model can easily get to ~92% accuracy (a random model would do 10%) with 4000 steps.\n",
    "\n",
    "Later we are going to define a CNN model to compare, and we just set a placeholder model here for now.\n",
    "\n",
    "> **Note**: \n",
    ">\n",
    "> * The code is here just to exemplify. We are actually using the same code from the [`mnist`](https://github.com/gomlx/gomlx/tree/main/examples/mnist) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=10: (Float32)[10 10]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "\t\"github.com/gomlx/gomlx/backends\"\n",
    "\t. \"github.com/gomlx/gomlx/pkg/core/graph\"\n",
    "\t\"github.com/gomlx/gomlx/pkg/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/pkg/ml/layers\"\n",
    ")\n",
    "\n",
    "var _ = NewGraph  // Make sure the graph package is in use.\n",
    "\n",
    "// LinearModelGraph builds a simple  model logistic model\n",
    "// It returns the logit, not the predictions, which works with most losses with shape `[batch_size, NumClasses]`.\n",
    "// inputs: only one tensor, with shape `[batch_size, width, height, depth]`.\n",
    "func LinearModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tctx = ctx.In(\"model\") // Create the model by default under the \"/model\" scope.\n",
    "\tbatchSize := inputs[0].Shape().Dimensions[0]\n",
    "\tembeddings := Reshape(inputs[0], batchSize, -1)\n",
    "\tlogits := layers.DenseWithBias(ctx, embeddings, mnist.NumClasses)\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "\n",
    "%% -set=\"batch_size=10\"\n",
    "// Let's test that the logits are coming out with the right shape: we want [batch_size, 10], since there are 10 classes.\n",
    "AssertDownloaded()\n",
    "ctx, _ := ContextFromSettings()\n",
    "g := NewGraph(backends.MustNew(), \"placeholder\")\n",
    "batchSize := context.GetParamOr(ctx, \"batch_size\", int(100))\n",
    "logits := LinearModelGraph(ctx, nil, []*Node{Parameter(g, \"images\", shapes.Make(DType, batchSize, mnist.Height, mnist.Width, mnist.Depth))})\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", batchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "With a model function defined, we use the training loop create for the MNIST.\n",
    "\n",
    "The trainer is provided in the [`mnist` package](https://github.com/gomlx/gomlx/tree/main/examples/mnist). It is straight forward (and almost the same for every different project) and does the following for us:\n",
    "\n",
    "- If a checkpoing is given (--checkpoint) and it has previously saved model, it loads hyperparmeters and trained variables.\n",
    "- Create trainer: with selected model function (see [Linear model](#Linear-model) and [Linear model for MNIST](#CNN-model-for-MNIST) sections), optimizer, loss and metrics.\n",
    "- Create a `train.Loop` and attach to it a progressbar, a periodic checkpoint saver and a plotter (`--set=\"plots=true\"`).\n",
    "- Train the selected number of train steps.\n",
    "- Report results.\n",
    "\n",
    "Below we train 4000 steps with the default settings just to check things are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear model:\n",
      "Backend stablehlo: stablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "\t- checkpoint in /home/janpf/work/mnist/linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"cb3b62d7\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- restarting from global step 4000\n",
      "\t - target train_steps=4000 already reached. To train further, set a number additional to current global step.\n",
      "\n",
      "Results on train:\n",
      "\tMean Loss+Regularization (#loss+): 0.287\n",
      "\tMean Loss (#loss): 0.287\n",
      "\tMean Accuracy (#acc): 92.07%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.284\n",
      "\tMean Loss (#loss): 0.284\n",
      "\tMean Accuracy (#acc): 92.09%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var flagCheckpoint = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    "\n",
    "// trainModel with hyperparameters configured with `-set=...`.\n",
    "func trainModel() {\n",
    "    ctx, paramsSet := ContextFromSettings()\n",
    "    must.M(mnist.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet))\n",
    "}\n",
    "\n",
    "// Train 50 steps, only to test things are working. No plots.\n",
    "%% --checkpoint=linear  --set=\"model=linear;train_steps=4000;plots=true\"\n",
    "trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model for MNIST\n",
    "\n",
    "Let's now properly define a CNN model to compare.\n",
    "\n",
    "The model was built following a [Deep MNIST for Experts](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/mnist/pros/index.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=10: (Float32)[10 10]\n"
     ]
    }
   ],
   "source": [
    "// CnnModelGraph builds the CNN model for our demo.\n",
    "// It returns the logit, not the predictions, which works with most losses with shape `[batch_size, NumClasses]`.\n",
    "// inputs: only one tensor, with shape `[batch_size, width, height, depth]`.\n",
    "func CnnModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tctx = ctx.In(\"model\") // Create the model by default under the \"/model\" scope.\n",
    "\tembeddings := CnnEmbeddings(ctx, inputs[0])\n",
    "\tlogits := layers.Dense(ctx, embeddings, true, mnist.NumClasses)\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "\n",
    "func CnnEmbeddings(ctx *context.Context, images *Node) *Node {\n",
    "\tbatchSize := images.Shape().Dimensions[0]\n",
    "\tg := images.Graph()\n",
    "\tdtype := images.DType()\n",
    "\n",
    "\tlayerIdx := 0\n",
    "\tnextCtx := func(name string) *context.Context {\n",
    "\t\tnewCtx := ctx.Inf(\"%03d_%s\", layerIdx, name)\n",
    "\t\tlayerIdx++\n",
    "\t\treturn newCtx\n",
    "\t}\n",
    "\t// Dropout.\n",
    "\tdropoutRate := context.GetParamOr(ctx, \"cnn_dropout_rate\", -1.0)\n",
    "\tif dropoutRate < 0 {\n",
    "\t\tdropoutRate = context.GetParamOr(ctx, layers.ParamDropoutRate, 0.0)\n",
    "\t}\n",
    "\tvar dropoutNode *Node\n",
    "\tif dropoutRate > 0.0 {\n",
    "\t\tdropoutNode = Scalar(g, dtype, dropoutRate)\n",
    "\t}\n",
    "\n",
    "\timages = layers.Convolution(nextCtx(\"conv\"), images).Filters(32).KernelSize(3).PadSame().Done()\n",
    "\timages.AssertDims(batchSize, 28, 28, 32)\n",
    "\timages = activations.Relu(images)\n",
    "\timages = normalizeCNN(nextCtx(\"norm\"), images)\n",
    "\timages = MaxPool(images).Window(2).Done()\n",
    "\timages.AssertDims(batchSize, 14, 14, 32)\n",
    "\n",
    "\timages = layers.Convolution(nextCtx(\"conv\"), images).Filters(64).KernelSize(3).PadSame().Done()\n",
    "\timages.AssertDims(batchSize, 14, 14, 64)\n",
    "\timages = activations.Relu(images)\n",
    "\timages = normalizeCNN(nextCtx(\"norm\"), images)\n",
    "\timages = MaxPool(images).Window(2).Done()\n",
    "\timages = layers.DropoutNormalize(nextCtx(\"dropout\"), images, dropoutNode, true)\n",
    "\timages.AssertDims(batchSize, 7, 7, 64)\n",
    "\n",
    "\t// Flatten images\n",
    "\timages = Reshape(images, batchSize, -1)\n",
    "\treturn images\n",
    "}\n",
    "\n",
    "func normalizeCNN(ctx *context.Context, logits *Node) *Node {\n",
    "\tnormalizationType := context.GetParamOr(ctx, \"cnn_normalization\", \"none\")\n",
    "\tswitch normalizationType {\n",
    "\tcase \"layer\":\n",
    "\t\tif logits.Rank() == 2 {\n",
    "\t\t\treturn layers.LayerNormalization(ctx, logits, -1).Done()\n",
    "\t\t} else if logits.Rank() == 4 {\n",
    "\t\t\treturn layers.LayerNormalization(ctx, logits, 2, 3).Done()\n",
    "\t\t} else {\n",
    "\t\t\treturn logits\n",
    "\t\t}\n",
    "\tcase \"batch\":\n",
    "\t\treturn batchnorm.New(ctx, logits, -1).Done()\n",
    "\tcase \"none\", \"\":\n",
    "\t\treturn logits\n",
    "\tdefault:\n",
    "\t\texceptions.Panicf(\"invalid normalization type %q -- set it with parameter %q\", normalizationType, \"cnn_normalization\")\n",
    "\t\treturn nil\n",
    "\t}\n",
    "}\n",
    "%% -set=\"batch_size=10\"\n",
    "// Let's test that the logits are coming out with the right shape: we want [batch_size, 10], since there are 10 classes.\n",
    "AssertDownloaded()\n",
    "ctx, _ := ContextFromSettings()\n",
    "g := NewGraph(backends.MustNew(), \"placeholder\")\n",
    "batchSize := context.GetParamOr(ctx, \"batch_size\", int(100))\n",
    "logits := CnnModelGraph(ctx, nil, []*Node{Parameter(g, \"images\", shapes.Make(DType, batchSize, mnist.Height, mnist.Width, mnist.Depth))})\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", batchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Training\n",
    "\n",
    "Let's train the CNN for real this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove a previously trained model\n",
    "!rm -rf ~/work/mnist/cnn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cnn model:\n",
      "Backend stablehlo: stablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "\t- checkpoint in /home/janpf/work/mnist/cnn\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m   0% [........................................] (94 steps/s) [0s:41s]\u001b[0m [step=35] [loss+=2.04] [~loss+=3.05] [~loss=3.05] [~acc=25.06%]          "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (511 steps/s)\u001b[0m [step=3999] [loss+=0.0247] [~loss+=0.0451] [~loss=0.0451] [~acc=98.52%]                \n",
      "\n",
      "\t- saving checkpoint@4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"591ce657\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[0.13530303537845612,0.19173917174339294,0.2548198401927948,0.32728397846221924,0.39659905433654785,0.4613094627857208,0.530718207359314,0.6037190556526184,0.6779119968414307,0.7459961175918579,0.8033071756362915,0.8511596918106079,0.8858914971351624,0.9106019139289856,0.9290866255760193,0.9426546692848206,0.9513494968414307,0.9591957330703735,0.9653608202934265,0.971001148223877,0.9751777052879333,0.9791073799133301,0.9822787642478943,0.9846959114074707,0.9852487444877625]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on train\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[0.2989666759967804,0.5166000127792358,0.6893166899681091,0.7736666798591614,0.8264999985694885,0.8583500385284424,0.8837500214576721,0.9036166667938232,0.9191666841506958,0.9311000108718872,0.940833330154419,0.9503333568572998,0.958133339881897,0.9642500281333923,0.9693833589553833,0.9743333458900452,0.9777166843414307,0.9812000393867493,0.9836166501045227,0.9859499931335449,0.9883833527565002,0.9897500276565552,0.9918166995048523,0.9932166934013367,0.9938833713531494]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[0.2888000011444092,0.5225000381469727,0.7031000256538391,0.7855000495910645,0.8369000554084778,0.8676000237464905,0.8915000557899475,0.9085000157356262,0.9259000420570374,0.9373000264167786,0.9470000267028809,0.9551000595092773,0.9616000652313232,0.9659000635147095,0.9718000292778015,0.9743000268936157,0.9773000478744507,0.9800000190734863,0.9814000725746155,0.9825000762939453,0.9855000376701355,0.9856000542640686,0.9876000285148621,0.9882000684738159,0.9889000654220581]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('591ce657', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"2b078406\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[3.48317551612854,2.4643383026123047,1.9493850469589233,1.6096751689910889,1.2534247636795044,1.1597225666046143,0.7735724449157715,0.6391029953956604,0.5414975881576538,0.43929460644721985,0.3626295030117035,0.2391061931848526,0.2652300298213959,0.241405189037323,0.21199440956115723,0.18102747201919556,0.15328708291053772,0.10472363978624344,0.13481193780899048,0.07511692494153976,0.07849088311195374,0.09612101316452026,0.08917001634836197,0.06115631386637688,0.02471723034977913]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[4.03750467300415,3.4787817001342773,3.020782232284546,2.6162824630737305,2.271580696105957,1.9831961393356323,1.6949597597122192,1.4049453735351562,1.1237763166427612,0.8734775185585022,0.6650710105895996,0.5005503296852112,0.38030728697776794,0.2988924980163574,0.23546959459781647,0.18975834548473358,0.1593945175409317,0.13258740305900574,0.11246027052402496,0.09454183280467987,0.07861976325511932,0.06747152656316757,0.05515103042125702,0.04795263707637787,0.04514594003558159]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[4.03750467300415,3.4787817001342773,3.020782232284546,2.6162824630737305,2.271580696105957,1.9831961393356323,1.6949597597122192,1.4049453735351562,1.1237763166427612,0.8734775185585022,0.6650710105895996,0.5005503296852112,0.38030728697776794,0.2988924980163574,0.23546959459781647,0.18975834548473358,0.1593945175409317,0.13258740305900574,0.11246027052402496,0.09454183280467987,0.07861976325511932,0.06747152656316757,0.05515103042125702,0.04795263707637787,0.04514594003558159]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on train\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[2.2095468044281006,1.4516105651855469,0.9845218658447266,0.7125254273414612,0.5489410161972046,0.4445273280143738,0.3675333559513092,0.3036819398403168,0.25605565309524536,0.21961644291877747,0.18699581921100616,0.1601952463388443,0.13578687608242035,0.11707969009876251,0.09911268204450607,0.08433976024389267,0.07240621000528336,0.0613788403570652,0.05317303165793419,0.045021094381809235,0.03823551535606384,0.032548870891332626,0.026436766609549522,0.02157766744494438,0.019844641909003258]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on train\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[2.2095468044281006,1.4516105651855469,0.9845218658447266,0.7125254273414612,0.5489410161972046,0.4445273280143738,0.3675333559513092,0.3036819398403168,0.25605565309524536,0.21961644291877747,0.18699581921100616,0.1601952463388443,0.13578687608242035,0.11707969009876251,0.09911268204450607,0.08433976024389267,0.07240621000528336,0.0613788403570652,0.05317303165793419,0.045021094381809235,0.03823551535606384,0.032548870891332626,0.026436766609549522,0.02157766744494438,0.019844641909003258]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[2.2040414810180664,1.4352821111679077,0.9632447957992554,0.6885784268379211,0.5261468291282654,0.4248254597187042,0.3496670424938202,0.2884123623371124,0.24181385338306427,0.20665901899337769,0.17536011338233948,0.14911994338035583,0.12723642587661743,0.11004385352134705,0.09307091683149338,0.07970709353685379,0.06938991695642471,0.060684360563755035,0.052846383303403854,0.04712763428688049,0.04224955663084984,0.03740571439266205,0.033711839467287064,0.03140505775809288,0.02974368818104267]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test\",\"x\":[11,23,37,54,74,98,127,162,204,254,314,386,472,575,699,848,1027,1242,1500,1810,2182,2628,3163,3805,4000],\"y\":[2.2040414810180664,1.4352821111679077,0.9632447957992554,0.6885784268379211,0.5261468291282654,0.4248254597187042,0.3496670424938202,0.2884123623371124,0.24181385338306427,0.20665901899337769,0.17536011338233948,0.14911994338035583,0.12723642587661743,0.11004385352134705,0.09307091683149338,0.07970709353685379,0.06938991695642471,0.060684360563755035,0.052846383303403854,0.04712763428688049,0.04224955663084984,0.03740571439266205,0.033711839467287064,0.03140505775809288,0.02974368818104267]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('2b078406', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- trained to step 4000, median train step: 1598 microseconds\n",
      "\n",
      "Results on train:\n",
      "\tMean Loss+Regularization (#loss+): 0.0198\n",
      "\tMean Loss (#loss): 0.0198\n",
      "\tMean Accuracy (#acc): 99.39%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.0297\n",
      "\tMean Loss (#loss): 0.0297\n",
      "\tMean Accuracy (#acc): 98.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% --checkpoint=cnn --set=\"model=cnn;train_steps=4000;plots=true\"\n",
    "trainModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "text/x-go",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.24.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
