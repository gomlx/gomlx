{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f431da81-4d94-4fd1-8a51-952ef824cb46",
   "metadata": {},
   "source": [
    "# IMDB Movie Review Dataset\n",
    "\n",
    "This is a library to download and parse the [IMDB's Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) dataset and a demo of a transformer based model. The dataset has 25K training, and 25K test dataset, plus 50K unlabeled examples.\n",
    "\n",
    "It's inspired on [Keras' Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/) demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f19ad-caa7-4d7d-8078-cbca680f2be2",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32600e05-745d-4c38-999a-3b96ca1502cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/gopjrt\" to local directory \"/home/janpf/Projects/gopjrt\".\n"
     ]
    }
   ],
   "source": [
    "!*rm -f go.work && go work init && go work use . \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/gopjrt\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e9e56-ef12-4d04-b7bb-99478fa2b662",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Downloading data files\n",
    "\n",
    "To download, uncompress and untar to the local directory, simply do the following. Notice if it's already downloaded in the given `--data` directory, it returns immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98ca191-0d4b-4e7c-ab24-ded6991b9671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"github.com/gomlx/gomlx/examples/imdb\"\n",
    "    \"github.com/gomlx/gomlx/pkg/support/fsutil\"\n",
    "    \"github.com/janpfeifer/must\"\n",
    "\n",
    "    _ \"github.com/gomlx/gomlx/backends/default\"\n",
    ")\n",
    "\n",
    "var (\n",
    "\tflagDataDir    = flag.String(\"data\", \"~/tmp/imdb\", \"Directory to cache downloaded and generated dataset files.\")\n",
    "\tflagEval       = flag.Bool(\"eval\", true, \"Whether to evaluate the model on the validation data in the end.\")\n",
    "\tflagVerbosity  = flag.Int(\"verbosity\", 1, \"Level of verbosity, the higher the more verbose.\")\n",
    "\tflagCheckpoint = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    ")\n",
    "\n",
    "func AssertDownloaded() {\n",
    "    *flagDataDir = must.M1(fsutil.ReplaceTildeInDir(*flagDataDir))\n",
    "    if !fsutil.MustFileExists(*flagDataDir) {\n",
    "        must.M(os.MkdirAll(*flagDataDir, 0777))\n",
    "    }\n",
    "    must.M(imdb.Download(*flagDataDir))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a415e2-8a29-4aeb-8809-b8d6b7ede5ad",
   "metadata": {},
   "source": [
    "### Sampling some examples\n",
    "\n",
    "It creates a small dataset and print out some random examples.\n",
    "\n",
    "It also defines the `DType`, used for all internal representations of the model, and the flag `--max_len` that defines the maximum number of tokens used per observation. This will beused in the modeling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bf2aab-7d50-4110-a8e3-bbee08063521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 0 - label 0]                                    │\n",
      "│    also dresses provocatively in every scene yet curses    │\n",
      "│    like a guy she gets very emotional when she fights      │\n",
      "│    with will smith for a while while trying to defend      │\n",
      "│    all women from bad guys everywhere the men are no       │\n",
      "│    better in this movie what we see is a bunch of          │\n",
      "│    idiots trying to do anything they can to win a date     │\n",
      "│    the males in this movie are concerned with getting      │\n",
      "│    either sexual favours or unable to speak clearly        │\n",
      "│    when face to face with a woman men in real life do      │\n",
      "│    not behave this way what we see in this movie is a      │\n",
      "│    product of culture gone awry everything is flip         │\n",
      "│    flopped guys act like girls girls act like guys all     │\n",
      "│    this is done while keeping the extreme predilections    │\n",
      "│    of the sexes very much a part of the story men are      │\n",
      "│    shown as soft and stupid but only interested in sex     │\n",
      "│    most of the time while women are shown as macho and     │\n",
      "│    overbearing but only as a veneer for their emotional    │\n",
      "│    insecurities this movie would be good if it wasn t      │\n",
      "│    presented obnoxiously to the audience the content is    │\n",
      "│    not the culprit it is the manner in which the           │\n",
      "│    content is presented                                    │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 1 - label 0]                                    │\n",
      "│    <START> some directors take 2 and a half hours to       │\n",
      "│    tell a story david lynch takes 2 and a half hours to    │\n",
      "│    piece together scenes with clues and his trademark      │\n",
      "│    oddity but there s never a story no plot no             │\n",
      "│    progression of the characters unless you find           │\n",
      "│    revealed delusion a progression it amazes me how        │\n",
      "│    anyone can call lynch s garbage art but if beauty       │\n",
      "│    rests in the eye of the beholder so be it lynch s       │\n",
      "│    movie and tv work in the 1980 s came off as avant       │\n",
      "│    garde and alternative fine 20 years later work like     │\n",
      "│    mulholland drive comes off as a 2 5 hour david lynch    │\n",
      "│    masturbation piece it s embarrasing i ve finally        │\n",
      "│    seen the movie that takes my top spot as the worst      │\n",
      "│    ever at least the people churning out godzilla and      │\n",
      "│    rodan weren t passing them off as art                   │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 2 - label 0]                                    │\n",
      "│    <START> for many year i saw this movie as a real        │\n",
      "│    movie of ninjas but after study more about this         │\n",
      "│    culture i can only think this is just another karate    │\n",
      "│    film a black shinobi and some weapons doesn t make a    │\n",
      "│    ninja it s much more than that the ninja are the        │\n",
      "│    most dangerous warrior of the japan because they are    │\n",
      "│    trained in every aspect of life to survive to           │\n",
      "│    anything killing whatever try to stop them this         │\n",
      "│    movie is not a about a ninja warrior just about a       │\n",
      "│    clown trying to be something he cannot even             │\n",
      "│    understand                                              │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import \"github.com/gomlx/gomlx/examples/imdb\"\n",
    "\n",
    "%%\n",
    "AssertDownloaded()\n",
    "imdb.PrintSample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8ca01-2c8f-4cd8-a644-850e928f64e1",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will create 3 different types of models for this demo: **Bag of Words** (**\"bow\"**), **Convolutionals** (**\"cnn\"**) and **Transformers** (**\"transformer\"**).\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "As with other demos we leverage the `context.Context` object to store all model and training parameters. \n",
    "One can set specific parameters using the `-set` command line flag.\n",
    "\n",
    "The [`imdb.CreateDefaultContext()`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/train.go) method sets all the default values for the hyperparameters that may be used by any of the 3 model types. The parameter \"model\" specify the model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad068f5e-46d9-411b-823c-0eae905da41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model types: [\"bow\" \"cnn\" \"transformer\"]\n",
      "\t\"/activation\": (string) \n",
      "\t\"/adam_dtype\": (string) \n",
      "\t\"/adam_epsilon\": (float64) 1e-07\n",
      "\t\"/batch_size\": (int) 32\n",
      "\t\"/cnn_dropout_rate\": (float64) 0.5\n",
      "\t\"/cnn_normalization\": (string) \n",
      "\t\"/cnn_num_layers\": (float64) 5\n",
      "\t\"/cosine_schedule_steps\": (int) 0\n",
      "\t\"/dropout_rate\": (float64) 0.1\n",
      "\t\"/eval_batch_size\": (int) 200\n",
      "\t\"/fnn_dropout_rate\": (float64) 0.3\n",
      "\t\"/fnn_normalization\": (string) \n",
      "\t\"/fnn_num_hidden_layers\": (int) 2\n",
      "\t\"/fnn_num_hidden_nodes\": (int) 32\n",
      "\t\"/fnn_residual\": (bool) true\n",
      "\t\"/imdb_content_max_len\": (int) 200\n",
      "\t\"/imdb_include_separators\": (bool) false\n",
      "\t\"/imdb_mask_word_task_weight\": (float64) 0\n",
      "\t\"/imdb_max_vocab\": (int) 20000\n",
      "\t\"/imdb_token_embedding_size\": (int) 32\n",
      "\t\"/imdb_use_unsupervised\": (bool) false\n",
      "\t\"/imdb_word_dropout_rate\": (float64) 0\n",
      "\t\"/l1_regularization\": (float64) 0\n",
      "\t\"/l2_regularization\": (float64) 0\n",
      "\t\"/learning_rate\": (float64) 0.0001\n",
      "\t\"/model\": (string) cnn\n",
      "\t\"/normalization\": (string) layer\n",
      "\t\"/num_checkpoints\": (int) 3\n",
      "\t\"/optimizer\": (string) adamw\n",
      "\t\"/plots\": (bool) true\n",
      "\t\"/train_steps\": (int) 5000\n",
      "\t\"/transformer_att_key_size\": (int) 8\n",
      "\t\"/transformer_dropout_rate\": (float64) -1\n",
      "\t\"/transformer_max_att_len\": (int) 200\n",
      "\t\"/transformer_num_att_heads\": (int) 2\n",
      "\t\"/transformer_num_att_layers\": (int) 1\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"golang.org/x/exp/maps\"\n",
    "    \"github.com/gomlx/gomlx/pkg/ml/context\"\n",
    ")\n",
    "\n",
    "// settings is bound to a \"-set\" flag to be used to set context hyperparameters.\n",
    "var settings = commandline.CreateContextSettingsFlag(imdb.CreateDefaultContext(), \"set\")\n",
    "\n",
    "// ContextFromSettings is the default context (createDefaultContext) changed by -set flag.\n",
    "// It also returns the list of parameters changed by -set in paramsSet: we use this later to avoid loading over the values from checkpoints.\n",
    "func ContextFromSettings() (ctx *context.Context, paramsSet []string) {\n",
    "    ctx = imdb.CreateDefaultContext()\n",
    "    paramsSet = must.M1(commandline.ParseContextSettings(ctx, *settings))\n",
    "    return ctx, paramsSet\n",
    "}\n",
    "\n",
    "%% -set=\"model=cnn\"\n",
    "fmt.Printf(\"Model types: %q\\n\", maps.Keys(imdb.ValidModels))\n",
    "ctx, _ := ContextFromSettings()\n",
    "fmt.Println(commandline.SprintContextSettings(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb816-6caf-46ea-805c-bd375834c55b",
   "metadata": {},
   "source": [
    "### Bag Of Words Model (bow)\n",
    "\n",
    "This is the simplest model we are going to train: it embeds each token of the sentence (default size of the is 32 numbers) sum them up, and pass that through a FNN.\n",
    "\n",
    "The [code in `imdb.BagOfWordsModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_bagofwords.go) looks like this:\n",
    "\n",
    "```go\n",
    "// BagOfWordsModelGraph builds the computation graph for the \"bag of words\" model: simply the sum of the embeddings\n",
    "// for each token included.\n",
    "func BagOfWordsModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tembed, _ := EmbedTokensGraph(ctx, inputs[0])\n",
    "\n",
    "\t// Take the max over the content length, and put an FNN on top.\n",
    "\t// Shape transformation: [batch_size, content_len, embed_size] -> [batch_size, embed_size]\n",
    "\tembed = ReduceMax(embed, 1)\n",
    "\tlogits := fnn.New(ctx, embed, 1).Done()\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "```\n",
    "\n",
    "We played a bit with the hyperparameters to get to ~85% accuracy on the validation data.\n",
    "\n",
    "The [code for `imdb.TrainModel` is here](https://github.com/gomlx/gomlx/blob/main/examples/imdb/train.go).\n",
    "It's a straight forward GoMLX training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cd517a-f592-4319-a9fd-acb8ab78124c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"stablehlo\":\tstablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "Model: bow\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m   7% [=>......................................] (639 steps/s) [0s:14s]\u001b[0m [step=719] [loss+=0.785] [~loss+=0.794] [~loss=0.682] [~acc=55.80%]        "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (2365 steps/s)\u001b[0m [step=9999] [loss+=0.32] [~loss+=0.33] [~loss=0.279] [~acc=88.72%]        %]        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"30011549\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5402533411979675,0.5392853021621704,0.5596029162406921,0.632577121257782,0.6870164275169373,0.7325926423072815,0.7615707516670227,0.7936610579490662,0.8070034980773926,0.8296061158180237,0.8525648713111877,0.869276762008667,0.8816903829574585,0.8871591091156006]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5,0.5281199812889099,0.6909199953079224,0.7739599943161011,0.7895599603652954,0.8084399700164795,0.8276799917221069,0.8472399711608887,0.8685199618339539,0.8871600031852722,0.9031599760055542,0.9178400039672852,0.9326799511909485,0.9338799715042114]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5,0.5288000106811523,0.6824399828910828,0.7529599666595459,0.7723199725151062,0.7876799702644348,0.8042399883270264,0.8177199959754944,0.8306399583816528,0.8398799896240234,0.8474799990653992,0.8509199619293213,0.853119969367981,0.8534799814224243]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('30011549', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"825aced5\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.8239019513130188,0.7825658917427063,0.7952867150306702,0.7503643035888672,0.719773530960083,0.7092522382736206,0.7051005959510803,0.6178226470947266,0.5290652513504028,0.5940009355545044,0.40306875109672546,0.3860255479812622,0.4759054481983185,0.3200609087944031]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.8194238543510437,0.8112613558769226,0.7941983342170715,0.7644442915916443,0.7168365716934204,0.6502681970596313,0.5804030299186707,0.5327412486076355,0.492558091878891,0.4517420828342438,0.40294912457466125,0.367053359746933,0.3392152786254883,0.32952880859375]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.6899962425231934,0.6898630857467651,0.6820388436317444,0.6617869734764099,0.6225388050079346,0.562140703201294,0.4975394904613495,0.45554256439208984,0.42109936475753784,0.3859061300754547,0.3425568640232086,0.3114994764328003,0.28769561648368835,0.2785656750202179]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.8208915591239929,0.8031015396118164,0.7819742560386658,0.7494954466819763,0.6897996664047241,0.6046567559242249,0.528451144695282,0.46906471252441406,0.41784268617630005,0.36872491240501404,0.32811304926872253,0.2893465459346771,0.25032347440719604,0.24494291841983795]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.6944933533668518,0.6850865483283997,0.6728652715682983,0.6492624282836914,0.5971245765686035,0.5175442695617676,0.44641536474227905,0.39256781339645386,0.3469811677932739,0.3034229576587677,0.26810505986213684,0.23407579958438873,0.19899334013462067,0.19418838620185852]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.8212147951126099,0.8038121461868286,0.7833364009857178,0.7521498799324036,0.6957464814186096,0.618066668510437,0.5526734590530396,0.506218433380127,0.46955597400665283,0.4351012110710144,0.4127872586250305,0.396352618932724,0.38565853238105774,0.3840710520744324]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.6948179602622986,0.6857978105545044,0.6742264628410339,0.6519162058830261,0.6030709147453308,0.5309540629386902,0.47063812613487244,0.42972123622894287,0.3986942172050476,0.36979955434799194,0.35277968645095825,0.341081827878952,0.334328830242157,0.333316832780838]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('825aced5', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 217 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.245\n",
      "\tMean Loss (#loss): 0.194\n",
      "\tMean Accuracy (#acc): 93.39%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.384\n",
      "\tMean Loss (#loss): 0.333\n",
      "\tMean Accuracy (#acc): 85.35%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=bow;l2_regularization=1e-3;learning_rate=1e-4;normalization=none;train_steps=10000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0d8ed-31ed-49ba-8b6f-1518d3df8a8d",
   "metadata": {},
   "source": [
    "### Convolution Model (cnn)\n",
    "\n",
    "The function [`imdb.CnnModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_cnn.go) creates a 1D convolution model, with arbitrary number of convolutions. After the convolution, it behaves the same way as the Bag Of Words model.\n",
    "\n",
    "The core of the convolution model looks like this:\n",
    "\n",
    "```go\n",
    "\t// 1D Convolution: embed is [batch_size, content_len, embed_size].\n",
    "\tnumConvolutions := context.GetParamOr(ctx, \"cnn_num_layers\", 5)\n",
    "\tlogits := embed\n",
    "\tfor convIdx := range numConvolutions {\n",
    "\t\tctx := ctx.Inf(\"%03d_conv\", convIdx)\n",
    "\t\tresidual := logits\n",
    "\t\tif convIdx > 0 {\n",
    "\t\t\tlogits = NormalizeSequence(ctx, logits)\n",
    "\t\t}\n",
    "\t\tlogits = layers.Convolution(ctx, embed).KernelSize(7).Filters(embedSize).Strides(1).Done()\n",
    "\t\tlogits = activations.ApplyFromContext(ctx, logits)\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tlogits = layers.Dropout(ctx, logits, dropoutNode)\n",
    "\t\t}\n",
    "\t\tif residual.Shape().Equal(logits.Shape()) {\n",
    "\t\t\tlogits = Add(logits, residual)\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Take the max over the content length, and put an FNN on top.\n",
    "\t// Shape transformation: [batch_size, content_len, embed_size] -> [batch_size, embed_size]\n",
    "\tlogits = ReduceMax(logits, 1)\n",
    "\tlogits = fnn.New(ctx, logits, 1).Done()\n",
    "\tlogits.AssertDims(batchSize, 1)\n",
    "```\n",
    "\n",
    "Notice how well it can overfit to the training data ... but it doesn't help the test results. To improve this one needs some careful regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77a72a8-2872-4c56-9065-e245deb85169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"stablehlo\":\tstablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "Model: cnn\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m   7% [=>......................................] (425 steps/s) [1s:21s]\u001b[0m [step=719] [loss+=1.39] [~loss+=1.39] [~loss=0.736] [~acc=52.33%]        "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (942 steps/s)\u001b[0m [step=9999] [loss+=0.25] [~loss+=0.273] [~loss=0.0894] [~acc=97.09%]        8%]        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"add48e36\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5149391889572144,0.5164487361907959,0.5200543403625488,0.5363680720329285,0.5981272459030151,0.7090290784835815,0.8057874441146851,0.8603236079216003,0.8941185474395752,0.9043624401092529,0.9335997700691223,0.9549718499183655,0.9719212651252747,0.9708905816078186]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5000799894332886,0.6017999649047852,0.5245999693870544,0.608519971370697,0.695639967918396,0.7648800015449524,0.8449999690055847,0.9058799743652344,0.9277600049972534,0.9519999623298645,0.9655199646949768,0.979479968547821,0.9884399771690369,0.9907999634742737]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.5,0.5620399713516235,0.5220000147819519,0.5731199979782104,0.6399199962615967,0.7316399812698364,0.8012399673461914,0.8382799625396729,0.8422399759292603,0.8481999635696411,0.8408799767494202,0.8388400077819824,0.8360399603843689,0.834119975566864]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('add48e36', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"01708ce8\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[1.5947164297103882,1.3705236911773682,1.3495779037475586,1.2521244287490845,1.1516757011413574,1.0677049160003662,0.7107961773872375,0.6363153457641602,0.4186595380306244,0.40404102206230164,0.5966446995735168,0.2461550533771515,0.20701219141483307,0.24971774220466614]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[1.5934574604034424,1.4809051752090454,1.3932859897613525,1.3065427541732788,1.1855919361114502,1.0151612758636475,0.81485515832901,0.6780970096588135,0.5758074522018433,0.522537112236023,0.4226790964603424,0.34505006670951843,0.27464571595191956,0.27334094047546387]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.8402268886566162,0.769553005695343,0.7373174428939819,0.7168058753013611,0.6687296032905579,0.5714346766471863,0.43077439069747925,0.3364470601081848,0.26919132471084595,0.24778763949871063,0.17830418050289154,0.12965695559978485,0.0867985337972641,0.08936896920204163]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[1.464152455329895,1.3664580583572388,1.3119817972183228,1.217331886291504,1.0926669836044312,0.9484019875526428,0.76480633020401,0.5972114205360413,0.5126475691795349,0.4148187041282654,0.35362374782562256,0.2822704315185547,0.22764809429645538,0.21839599311351776]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.7258200645446777,0.673882007598877,0.6754074096679688,0.6461113095283508,0.592282772064209,0.517440676689148,0.3883189260959625,0.2602337896823883,0.2095523625612259,0.14282000064849854,0.11142367124557495,0.06855308264493942,0.04117417708039284,0.03575458005070686]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[1.468509316444397,1.3756077289581299,1.325517177581787,1.241599678993225,1.1280040740966797,0.992749810218811,0.8633740544319153,0.7725917100906372,0.751920223236084,0.7110399603843689,0.7780612111091614,0.8078455328941345,0.8620367050170898,0.8927142024040222]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5200,6441,7930,9717,10000],\"y\":[0.7301766872406006,0.6830316185951233,0.6889434456825256,0.6703788638114929,0.6276198029518127,0.5617890357971191,0.4868873953819275,0.43561431765556335,0.44882556796073914,0.43904173374176025,0.5358608365058899,0.5941280126571655,0.6755622625350952,0.7100734114646912]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('01708ce8', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 580 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.218\n",
      "\tMean Loss (#loss): 0.0358\n",
      "\tMean Accuracy (#acc): 99.08%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.893\n",
      "\tMean Loss (#loss): 0.71\n",
      "\tMean Accuracy (#acc): 83.41%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=cnn;l2_regularization=1e-3;learning_rate=1e-4;normalization=layer;train_steps=10000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adcb51-2190-4cfc-9224-07f7331bae41",
   "metadata": {},
   "source": [
    "### Transformer Model\n",
    "\n",
    "Finally a Transformer version of the model, as defined in the [\"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) famous paper. \n",
    "\n",
    "Notice it's not significantly better than our previous simple Bag-Of-Words model. Likely because there is not enough data for the transformer to make any difference. The success of transformers in large-language-models is in large part due to the training with huge amounts of unsupervised (or self-supervised) data, but that is beyond the scope of this small test.\n",
    "\n",
    "The code is in [`imdb.TransformerModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_transformer.go), and the core of it looks like this:\n",
    "\n",
    "```go\n",
    "    ...\n",
    "\t// Add the requested number of attention layers.\n",
    "\tnumAttLayers := context.GetParamOr(ctx, \"transformer_num_att_layers\", 1)\n",
    "\tnumAttHeads := context.GetParamOr(ctx, \"transformer_num_att_heads\", 2)\n",
    "\tattKeySize := context.GetParamOr(ctx, \"transformer_att_key_size\", 8)\n",
    "\tfor layerNum := range numAttLayers {\n",
    "\t\t// Each layer in its own scope.\n",
    "\t\tctx := ctx.Inf(\"%03d_attention_layer\", layerNum)\n",
    "\t\tresidual := embed\n",
    "\t\tembed = layers.MultiHeadAttention(ctx.In(\"000_attention\"), embed, embed, embed, numAttHeads, attKeySize).\n",
    "\t\t\tSetKeyMask(mask).SetQueryMask(mask).\n",
    "\t\t\tSetOutputDim(embedSize).\n",
    "\t\t\tSetValueHeadDim(embedSize).Done()\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tembed = layers.Dropout(ctx.In(\"001_dropout\"), embed, dropoutNode)\n",
    "\t\t}\n",
    "\t\tembed = NormalizeSequence(ctx.In(\"002_normalization\"), embed)\n",
    "\t\tattentionOutput := embed\n",
    "\n",
    "\t\t// Transformers recipe: 2 dense layers after attention.\n",
    "\t\tembed = fnn.New(ctx.In(\"003_fnn\"), embed, embedSize).NumHiddenLayers(1, embedSize).Done()\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tembed = layers.Dropout(ctx.In(\"004_dropout\"), embed, dropoutNode)\n",
    "\t\t}\n",
    "\t\tembed = Add(embed, attentionOutput)\n",
    "\t\tembed = NormalizeSequence(ctx.In(\"005_normalization\"), embed)\n",
    "\n",
    "\t\t// Residual connection:\n",
    "\t\tif layerNum > 0 {\n",
    "\t\t\tembed = Add(residual, embed)\n",
    "\t\t}\n",
    "\t}\n",
    "    ...\n",
    "```\n",
    "\n",
    "With only 5000 steps we got ~87% on the test data -- and significant overfitting as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ac0032-de61-4573-88db-fbac6730ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"stablehlo\":\tstablehlo:cuda - PJRT \"cuda\" plugin (/home/janpf/.local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.76 [StableHLO]\n",
      "Model: transformer\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m  14% [====>...................................] (418 steps/s) [2s:10s]\u001b[0m [step=724] [loss+=1.34] [~loss+=1.54] [~loss=1.14] [~acc=50.92%]         "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[1m 100% [========================================] (697 steps/s)\u001b[0m [step=4999] [loss+=0.541] [~loss+=0.626] [~loss=0.286] [~acc=89.05%]                \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"d63cc2da\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.52680504322052,0.5066558718681335,0.5072829723358154,0.5124550461769104,0.5402949452400208,0.6202234625816345,0.6932973861694336,0.7729853391647339,0.8541246056556702,0.8905036449432373]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.5,0.5,0.5,0.605239987373352,0.5918399691581726,0.6891199946403503,0.7929999828338623,0.8455599546432495,0.879319965839386,0.9082799553871155]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Accuracy on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[0.5,0.5,0.5,0.5400399565696716,0.5286799669265747,0.6346799731254578,0.6933199763298035,0.7930799722671509,0.8278799653053284,0.8606399893760681]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('d63cc2da', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"753233a0\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.34.0.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[3.548882484436035,1.9468510150909424,1.1653386354446411,1.072594404220581,1.0773931741714478,1.0567080974578857,0.9792926907539368,0.812250018119812,0.633646547794342,0.5406325459480286]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[8.339265823364258,3.2378551959991455,1.5258185863494873,1.1304655075073242,1.0664317607879639,1.035007357597351,0.9915756583213806,0.8948150277137756,0.7233933210372925,0.6258135437965393]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[7.933467864990234,2.837958812713623,1.1322914361953735,0.7437993288040161,0.6875929236412048,0.6645559072494507,0.6297044157981873,0.5409465432167053,0.3756648898124695,0.28576838970184326]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[2.619462490081787,1.2531756162643433,1.091762661933899,1.073803186416626,1.0557771921157837,1.0263773202896118,0.984836757183075,0.8869556784629822,0.7287977337837219,0.6164700388908386]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on train-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[2.216050386428833,0.8556900024414062,0.7002630829811096,0.6890788078308105,0.6787495017051697,0.6574711799621582,0.6242779493331909,0.5339714288711548,0.381759375333786,0.2775537371635437]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss+Regularization on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[3.040539026260376,1.3896490335464478,1.1125617027282715,1.0762510299682617,1.0701402425765991,1.0367786884307861,1.0030310153961182,0.9141952991485596,0.7802234888076782,0.6845622658729553]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Mean Loss on test-eval\",\"x\":[201,441,729,1075,1490,1988,2586,3304,4166,5000],\"y\":[2.637127637863159,0.9921634197235107,0.7210608124732971,0.6915265321731567,0.6931121945381165,0.667872965335846,0.6424717307090759,0.561212420463562,0.4331848621368408,0.3456457257270813]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"title\":{\"text\":\"Steps\"},\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('753233a0', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 5000] median train step: 764 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.616\n",
      "\tMean Loss (#loss): 0.278\n",
      "\tMean Accuracy (#acc): 90.83%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.685\n",
      "\tMean Loss (#loss): 0.346\n",
      "\tMean Accuracy (#acc): 86.06%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=transformer;normalization=none;activation=swish;l2_regularization=1e-3;cnn_dropout_rate=0.5;fnn_dropout_rate=0.3;learning_rate=1e-4;train_steps=5000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "text/x-go",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.24.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
