// *** DO NOT EDIT ***: File generated by internal/cmd/alternates_generator.
// - Base source file (edit this one): convgeneral_exec.go
// - Tag used for this generation: full

// Copyright 2023-2026 The GoMLX Authors. SPDX-License-Identifier: Apache-2.0

package simplego

import "github.com/gomlx/gomlx/pkg/core/dtypes/bfloat16"

type _ = bfloat16.BFloat16

// This file serves the "base" version of the `execConv*` functions, as well as a template.
//
// The other versions are generated by `internal/cmd/alternates_generator`, where each line is generated
//alt:tag1|tag2"  // according to a pre-set selection of tags. Lines marked with " are included or excluded
// according to the tags.
//alt:base"  // The " tag indicates it's included in this base version, but will be removed in others.

// execConv* family of functions are used for ConvGeneral operations.
//
// The functions are generated by `internal/cmd/alternates_generator` based on the tags.
//
// The functions are generated for the following tags:
//
// execConvNoDilationGeneric: `base` tag; generics for native Go numeric types, no dilation or grouping handling, but faster.
// execConvBFloat16: `bf16` tag; supports BFloat16, fast but no dilation or grouping handling.
// execConvGeneric: `full`; support dilation and grouping, with a latency penalty.
// execConvBFloat16: `full_bf16` tag
//
//alt:base func execConvNoDilationGeneric[T PODNumericConstraints](plan convGeneralExecPlan) error {
//alt:bf16  func execConvNoDilationBFloat16(plan convGeneralExecPlan) error {
func execConvGeneric[T PODNumericConstraints](plan convGeneralExecPlan) error { //alt:full
	//alt:full_bf16  func execConvBFloat16(plan convGeneralExecPlan) error {

	// Shortcuts (and maybe move these values to the stack for faster access)
	inputFlat := plan.inputFlat.([]T)   //alt:base|full
	kernelFlat := plan.kernelFlat.([]T) //alt:base|full
	outputFlat := plan.outputFlat.([]T) //alt:base|full
	//alt:bf16|full_bf16  inputFlat := plan.inputFlat.([]bfloat16.BFloat16)
	//alt:bf16|full_bf16  kernelFlat := plan.kernelFlat.([]bfloat16.BFloat16)
	//alt:bf16|full_bf16  outputFlat := plan.outputFlat.([]bfloat16.BFloat16)
	inputShape := plan.inputShape
	kernelShape := plan.kernelShape
	outputShape := plan.outputShape
	rank := outputShape.Rank() // same rank for input and kernel.
	//spatialRank := rank - 2
	params := plan.params
	axes := params.axes
	paddings := params.paddings
	convStrides := params.strides

	inputBatchAxis := axes.InputBatch
	inputChannelsAxis := axes.InputChannels
	inputSpatialDims := params.dilatedInputSpatialDims
	inputSpatialStrides := params.inputSpatialStrides
	inputDilations := params.inputDilations                                                      //alt:full|full_bf16
	kernelDilations := params.kernelDilations                                                    //alt:full|full_bf16
	batchGroupCount := params.batchGroupCount                                                    //alt:full|full_bf16
	outputBatchSize := outputShape.Dimensions[inputBatchAxis]                                    //alt:full|full_bf16
	channelGroupCount := params.channelGroupCount                                                //alt:full|full_bf16
	numOutputChannelsPerGroup := outputShape.Dimensions[axes.OutputChannels] / channelGroupCount //alt:full|full_bf16

	outputBatchAxis := axes.OutputBatch
	outputChannelsAxis := axes.OutputChannels
	outputSpatialAxes := axes.OutputSpatial
	kernelInputChannelsAxis := axes.KernelInputChannels
	kernelOutputChannelsAxis := axes.KernelOutputChannels
	kernelSpatialAxes := axes.KernelSpatial
	kernelNumInputChannels := kernelShape.Dimensions[kernelInputChannelsAxis]

	// Indices we'll be iterating over.
	var outputFlatIdx int

	// Indices and strides: note we don't use an inputIndices because we only keep an inputFlatIndex.
	outputIndices := make([]int, rank)
	kernelIndices := make([]int, rank)

	inputStrides := inputShape.Strides()
	kernelStrides := kernelShape.Strides()

	// Loop sequentially over all output positions:
	for outputFlatIdx, outputIndices = range outputShape.IterOn(outputIndices) {
		batchIdx := outputIndices[outputBatchAxis]
		outputChannel := outputIndices[outputChannelsAxis]
		if batchGroupCount > 1 { //alt:full|full_bf16
			subBatchIdx := outputChannel / batchGroupCount    //alt:full|full_bf16
			batchIdx = subBatchIdx*outputBatchSize + batchIdx //alt:full|full_bf16
		} //alt:full|full_bf16
		baseInputFlatIdx := batchIdx * inputStrides[inputBatchAxis]

		// Loop over the kernel spatial axes, with the outputChannel given by the output loop.
		kernelIndices[kernelOutputChannelsAxis] = outputChannel
		var outputValue T //alt:base|full
		//alt:bf16|full_bf16  var outputValue float32
		var kernelFlatIdx int
	kernelLoop:
		for kernelFlatIdx, kernelIndices = range kernelShape.IterOnAxes(kernelSpatialAxes, kernelStrides, kernelIndices) {
			// Calculate the corresponding position in the input.
			inputFlatIdx := baseInputFlatIdx
			for spatialIdx, kernelSpatialAxis := range axes.KernelSpatial {
				kernelIdx := kernelIndices[kernelSpatialAxis]
				kernelDilation := kernelDilations[spatialIdx] //alt:full|full_bf16
				kernelIdx *= kernelDilation                   //alt:full|full_bf16
				outputSpatialAxis := outputSpatialAxes[spatialIdx]
				outputIdx := outputIndices[outputSpatialAxis]
				inputIdx := outputIdx*convStrides[spatialIdx] + kernelIdx - paddings[spatialIdx][0]
				inputDilation := inputDilations[spatialIdx] //alt:full|full_bf16
				//alt:base|bf16 if inputIdx < 0 || inputIdx >= inputSpatialDims[spatialIdx] {
				if inputIdx < 0 || inputIdx >= inputSpatialDims[spatialIdx] || (inputDilation > 1 && inputIdx%inputDilation != 0) { //alt:full|full_bf16
					// Index is in the padded area, we can move to the next kernel position.
					continue kernelLoop
				}
				inputIdx /= inputDilation // Make the dilated index back to the original input. //alt:full|full_bf16
				inputFlatIdx += inputIdx * inputSpatialStrides[spatialIdx]
			}

			// Accumulate over all the kernel/input channels.
			inputChannelStride := inputStrides[inputChannelsAxis]
			kernelChannelStride := kernelStrides[kernelInputChannelsAxis]
			if channelGroupCount > 1 { //alt:full|full_bf16
				featureGroup := outputChannel / numOutputChannelsPerGroup                    //alt:full|full_bf16
				inputFlatIdx += inputChannelStride * (featureGroup * kernelNumInputChannels) //alt:full|full_bf16
			} //alt:full|full_bf16
			for range kernelNumInputChannels {
				inputValue := inputFlat[inputFlatIdx]
				kernelValue := kernelFlat[kernelFlatIdx]
				outputValue += inputValue * kernelValue //alt:base|full
				//alt:bf16|full_bf16  outputValue += inputValue.Float32() * kernelValue.Float32()
				inputFlatIdx += inputChannelStride
				kernelFlatIdx += kernelChannelStride
			}
		}

		// Update output with accumulated value from the convolution of the kernel at this position.
		outputFlat[outputFlatIdx] = outputValue //alt:base|full
		//alt:bf16|full_bf16  outputFlat[outputFlatIdx] = bfloat16.FromFloat32(outputValue)
	}
	return nil
}
