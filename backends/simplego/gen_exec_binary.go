/***** File generated by ./internal/cmd/simplego_generator. Don't edit it directly. *****/

package simplego

import (
	"math"

	"github.com/gomlx/gomlx/backends"
	"github.com/gomlx/gomlx/pkg/core/shapes"
	"github.com/gomlx/gopjrt/dtypes"
	"github.com/gomlx/gopjrt/dtypes/bfloat16"
	"github.com/pkg/errors"
)

func init() {
	nodeExecutors[backends.OpTypeAdd] = execAdd
	nodeExecutors[backends.OpTypeMul] = execMul
	nodeExecutors[backends.OpTypeSub] = execSub
	nodeExecutors[backends.OpTypeDiv] = execDiv
	nodeExecutors[backends.OpTypeRem] = execRem
	nodeExecutors[backends.OpTypePow] = execPow
	nodeExecutors[backends.OpTypeMax] = execMax
	nodeExecutors[backends.OpTypeMin] = execMin
	nodeExecutors[backends.OpTypeBitwiseAnd] = execBitwiseAnd
	nodeExecutors[backends.OpTypeBitwiseOr] = execBitwiseOr
	nodeExecutors[backends.OpTypeBitwiseXor] = execBitwiseXor
	nodeExecutors[backends.OpTypeLogicalAnd] = execLogicalAnd
	nodeExecutors[backends.OpTypeLogicalOr] = execLogicalOr
	nodeExecutors[backends.OpTypeLogicalXor] = execLogicalXor
	nodeExecutors[backends.OpTypeEqual] = execEqual
	nodeExecutors[backends.OpTypeNotEqual] = execNotEqual
	nodeExecutors[backends.OpTypeGreaterOrEqual] = execGreaterOrEqual
	nodeExecutors[backends.OpTypeGreaterThan] = execGreaterThan
	nodeExecutors[backends.OpTypeLessOrEqual] = execLessOrEqual
	nodeExecutors[backends.OpTypeLessThan] = execLessThan
}

// execAdd executes the binary op Add.
func execAdd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape) // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execAddNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execAddNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execAddNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execAddNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execAddNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execAddNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execAddNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execAddNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execAddNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execAddNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execAddNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execAddNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input + c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input + rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] + rhs[rhsIdx]
		}
	}
	return
}

func execAddNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a + c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a + b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a + b)
		}
	}
	return
}

// execMul executes the binary op Mul.
func execMul(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape) // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execMulNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execMulNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execMulNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execMulNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execMulNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execMulNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execMulNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execMulNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execMulNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execMulNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execMulNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execMulNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input * c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input * rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] * rhs[rhsIdx]
		}
	}
	return
}

func execMulNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a * c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a * b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a * b)
		}
	}
	return
}

// execSub executes the binary op Sub.
func execSub(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execSubNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execSubNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execSubNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execSubNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execSubNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execSubNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execSubNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execSubNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execSubNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execSubNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execSubNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execSubNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input - c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c - input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input - rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] - rhs[rhsIdx]
		}
	}
	return
}

func execSubNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a - c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(c - a)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a - b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a - b)
		}
	}
	return
}

// execDiv executes the binary op Div.
func execDiv(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execDivNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execDivNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execDivNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execDivNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execDivNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execDivNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execDivNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execDivNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execDivNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execDivNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execDivNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execDivNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input / c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c / input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input / rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] / rhs[rhsIdx]
		}
	}
	return
}

func execDivNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a / c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(c / a)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a / b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a / b)
		}
	}
	return
}

// execRem executes the binary op Rem.
func execRem(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execRemIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execRemIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execRemIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execRemIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execRemIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execRemIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execRemIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execRemIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execRemFloatGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execRemFloatGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execRemFloatBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execRemIntegerGeneric[T PODIntegerConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input % c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c % input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input % rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] % rhs[rhsIdx]
		}
	}
	return
}

func execRemFloatGeneric[T PODFloatConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = T(math.Mod(float64(input), float64(c)))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = T(math.Mod(float64(c), float64(input)))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = T(math.Mod(float64(input), float64(rhs[ii])))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = T(math.Mod(float64(lhs[lhsIdx]), float64(rhs[rhsIdx])))
		}
	}
	return
}

func execRemFloatBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(c))))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Mod(float64(c), float64(a))))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(b))))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(b))))
		}
	}
	return
}

// execPow executes the binary op Pow.
func execPow(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execPowIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execPowIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execPowIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execPowIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execPowIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execPowIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execPowIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execPowIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execPowFloatGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execPowFloatGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execPowFloatBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execPowIntegerGeneric[T PODIntegerConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = execScalarPowIntGeneric(input, c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = execScalarPowIntGeneric(c, input)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = execScalarPowIntGeneric(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = execScalarPowIntGeneric(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execPowFloatGeneric[T PODFloatConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = T(math.Pow(float64(input), float64(c)))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = T(math.Pow(float64(c), float64(input)))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = T(math.Pow(float64(input), float64(rhs[ii])))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = T(math.Pow(float64(lhs[lhsIdx]), float64(rhs[rhsIdx])))
		}
	}
	return
}

func execPowFloatBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(c))))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Pow(float64(c), float64(a))))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(b))))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(b))))
		}
	}
	return
}

// execMax executes the binary op Max.
func execMax(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape) // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execMaxNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execMaxNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execMaxNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execMaxNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execMaxNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execMaxNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execMaxNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execMaxNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execMaxNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execMaxNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execMaxNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execMaxNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = max(input, c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = max(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = max(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execMaxNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(max(a, c))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(max(a, b))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(max(a, b))
		}
	}
	return
}

// execMin executes the binary op Min.
func execMin(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape) // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execMinNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execMinNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execMinNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execMinNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execMinNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execMinNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execMinNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execMinNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execMinNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execMinNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execMinNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execMinNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = min(input, c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = min(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = min(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execMinNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(min(a, c))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(min(a, b))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(min(a, b))
		}
	}
	return
}

// execBitwiseAnd executes the binary op BitwiseAnd.
func execBitwiseAnd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execBitwiseAndIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execBitwiseAndIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execBitwiseAndIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execBitwiseAndIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execBitwiseAndIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execBitwiseAndIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execBitwiseAndIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execBitwiseAndIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execBitwiseAndIntegerGeneric[T PODIntegerConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input & c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c & input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input & rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] & rhs[rhsIdx]
		}
	}
	return
}

// execBitwiseOr executes the binary op BitwiseOr.
func execBitwiseOr(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execBitwiseOrIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execBitwiseOrIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execBitwiseOrIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execBitwiseOrIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execBitwiseOrIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execBitwiseOrIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execBitwiseOrIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execBitwiseOrIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execBitwiseOrIntegerGeneric[T PODIntegerConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input | c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c | input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input | rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] | rhs[rhsIdx]
		}
	}
	return
}

// execBitwiseXor executes the binary op BitwiseXor.
func execBitwiseXor(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execBitwiseXorIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execBitwiseXorIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execBitwiseXorIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execBitwiseXorIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execBitwiseXorIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execBitwiseXorIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execBitwiseXorIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execBitwiseXorIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execBitwiseXorIntegerGeneric[T PODIntegerConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input ^ c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c ^ input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input ^ rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] ^ rhs[rhsIdx]
		}
	}
	return
}

// execLogicalAnd executes the binary op LogicalAnd.
func execLogicalAnd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalAndBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execLogicalAndBooleanGeneric[T PODBooleanConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input && c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c && input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input && rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] && rhs[rhsIdx]
		}
	}
	return
}

// execLogicalOr executes the binary op LogicalOr.
func execLogicalOr(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalOrBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execLogicalOrBooleanGeneric[T PODBooleanConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input || c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c || input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input || rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] || rhs[rhsIdx]
		}
	}
	return
}

// execLogicalXor executes the binary op LogicalXor.
func execLogicalXor(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalXorBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execLogicalXorBooleanGeneric[T PODBooleanConstraints](lhs, rhs []T, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input != c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c != input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input != rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] != rhs[rhsIdx]
		}
	}
	return
}

// execEqual executes the binary op Equal.
func execEqual(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execEqualNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execEqualNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execEqualNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execEqualNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execEqualNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execEqualNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execEqualNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execEqualNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execEqualNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execEqualNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execEqualNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execEqualNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input == c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input == rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] == rhs[rhsIdx]
		}
	}
	return
}

func execEqualNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a == c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a == b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a == b
		}
	}
	return
}

// execNotEqual executes the binary op NotEqual.
func execNotEqual(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape // Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execNotEqualNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execNotEqualNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execNotEqualNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execNotEqualNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execNotEqualNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execNotEqualNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execNotEqualNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execNotEqualNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execNotEqualNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execNotEqualNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execNotEqualNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execNotEqualNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input != c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input != rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] != rhs[rhsIdx]
		}
	}
	return
}

func execNotEqualNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a != c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a != b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a != b
		}
	}
	return
}

// execGreaterOrEqual executes the binary op GreaterOrEqual.
func execGreaterOrEqual(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execGreaterOrEqualNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execGreaterOrEqualNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execGreaterOrEqualNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execGreaterOrEqualNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execGreaterOrEqualNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execGreaterOrEqualNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execGreaterOrEqualNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execGreaterOrEqualNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execGreaterOrEqualNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execGreaterOrEqualNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execGreaterOrEqualNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execGreaterOrEqualNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input >= c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c >= input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input >= rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] >= rhs[rhsIdx]
		}
	}
	return
}

func execGreaterOrEqualNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a >= c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = c >= a
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a >= b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a >= b
		}
	}
	return
}

// execGreaterThan executes the binary op GreaterThan.
func execGreaterThan(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execGreaterThanNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execGreaterThanNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execGreaterThanNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execGreaterThanNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execGreaterThanNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execGreaterThanNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execGreaterThanNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execGreaterThanNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execGreaterThanNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execGreaterThanNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execGreaterThanNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execGreaterThanNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input > c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c > input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input > rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] > rhs[rhsIdx]
		}
	}
	return
}

func execGreaterThanNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a > c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = c > a
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a > b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a > b
		}
	}
	return
}

// execLessOrEqual executes the binary op LessOrEqual.
func execLessOrEqual(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execLessOrEqualNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execLessOrEqualNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execLessOrEqualNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execLessOrEqualNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execLessOrEqualNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execLessOrEqualNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execLessOrEqualNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execLessOrEqualNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execLessOrEqualNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execLessOrEqualNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execLessOrEqualNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execLessOrEqualNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input <= c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c <= input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input <= rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] <= rhs[rhsIdx]
		}
	}
	return
}

func execLessOrEqualNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a <= c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = c <= a
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a <= b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a <= b
		}
	}
	return
}

// execLessThan executes the binary op LessThan.
func execLessThan(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) (*Buffer, error) {
	lhs, rhs := inputs[0], inputs[1]
	lhsIsScalarOr1, rhsIsScalarOr1 := lhs.shape.Size() == 1, rhs.shape.Size() == 1
	output := backend.getBuffer(node.shape.DType, node.shape.Size())
	output.shape = node.shape
	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch lhs.shape.DType {

	case dtypes.Uint8:
		execLessThanNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint16:
		execLessThanNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint32:
		execLessThanNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Uint64:
		execLessThanNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int8:
		execLessThanNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int16:
		execLessThanNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int32:
		execLessThanNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Int64:
		execLessThanNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float32:
		execLessThanNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.Float64:
		execLessThanNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)

	case dtypes.BFloat16:
		execLessThanNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bool), lhs.shape, rhs.shape, output.shape)
	default:
		return nil, errors.Errorf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output, nil
}

func execLessThanNumericGeneric[T PODNumericConstraints](lhs, rhs []T, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input < c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c < input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input < rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] < rhs[rhsIdx]
		}
	}
	return
}

func execLessThanNumericBFloat16(lhs, rhs []bfloat16.BFloat16, output []bool,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = a < c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = c < a
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = a < b
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = a < b
		}
	}
	return
}
