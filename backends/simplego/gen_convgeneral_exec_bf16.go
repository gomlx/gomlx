// *** DO NOT EDIT ***: File generated by internal/cmd/alternates_generator.
// - Base source file (edit this one): convgeneral_exec.go
// - Tag used for this generation: bf16

// Copyright 2023-2026 The GoMLX Authors. SPDX-License-Identifier: Apache-2.0

package simplego

import "github.com/gomlx/gomlx/pkg/core/dtypes/bfloat16"

type _ = bfloat16.BFloat16

// This file serves the "base" version of the `execConv*` functions, as well as a template.
//
// The other versions are generated by `internal/cmd/alternates_generator`, where each line is generated
//alt:tag1|tag2"  // according to a pre-set selection of tags. Lines marked with " are included or excluded
// according to the tags.
//alt:base"  // The " tag indicates it's included in this base version, but will be removed in others.

// execConv* family of functions are used for ConvGeneral operations.
//
// The functions are generated by `internal/cmd/alternates_generator` based on the tags.
//
// The functions are generated for the following tags:
//
// execConvNoDilationGeneric: `base` tag; generics for native Go numeric types, no dilation or grouping handling, but faster.
// execConvBFloat16: `bf16` tag; supports BFloat16, fast but no dilation or grouping handling.
// execConvGeneric: `full`; support dilation and grouping, with a latency penalty.
// execConvBFloat16: `full_bf16` tag
//
//alt:base func execConvNoDilationGeneric[T PODNumericConstraints](plan convGeneralExecPlan) error {
func execConvNoDilationBFloat16(plan convGeneralExecPlan) error { //alt:bf16
	//alt:full  func execConvGeneric[T PODNumericConstraints](plan convGeneralExecPlan) error {
	//alt:full_bf16  func execConvBFloat16(plan convGeneralExecPlan) error {

	// Shortcuts (and maybe move these values to the stack for faster access)
	//alt:base|full inputFlat := plan.inputFlat.([]T)
	//alt:base|full kernelFlat := plan.kernelFlat.([]T)
	//alt:base|full outputFlat := plan.outputFlat.([]T)
	inputFlat := plan.inputFlat.([]bfloat16.BFloat16)   //alt:bf16|full_bf16
	kernelFlat := plan.kernelFlat.([]bfloat16.BFloat16) //alt:bf16|full_bf16
	outputFlat := plan.outputFlat.([]bfloat16.BFloat16) //alt:bf16|full_bf16
	inputShape := plan.inputShape
	kernelShape := plan.kernelShape
	outputShape := plan.outputShape
	rank := outputShape.Rank() // same rank for input and kernel.
	//spatialRank := rank - 2
	params := plan.params
	axes := params.axes
	paddings := params.paddings
	convStrides := params.strides

	inputBatchAxis := axes.InputBatch
	inputChannelsAxis := axes.InputChannels
	inputSpatialDims := params.dilatedInputSpatialDims
	inputSpatialStrides := params.inputSpatialStrides
	//alt:full|full_bf16  inputDilations := params.inputDilations
	//alt:full|full_bf16  kernelDilations := params.kernelDilations
	//alt:full|full_bf16  batchGroupCount := params.batchGroupCount
	//alt:full|full_bf16  outputBatchSize := outputShape.Dimensions[inputBatchAxis]
	//alt:full|full_bf16  channelGroupCount := params.channelGroupCount
	//alt:full|full_bf16  numOutputChannelsPerGroup := outputShape.Dimensions[axes.OutputChannels] / channelGroupCount

	outputBatchAxis := axes.OutputBatch
	outputChannelsAxis := axes.OutputChannels
	outputSpatialAxes := axes.OutputSpatial
	kernelInputChannelsAxis := axes.KernelInputChannels
	kernelOutputChannelsAxis := axes.KernelOutputChannels
	kernelSpatialAxes := axes.KernelSpatial
	kernelNumInputChannels := kernelShape.Dimensions[kernelInputChannelsAxis]

	// Indices we'll be iterating over.
	var outputFlatIdx int

	// Indices and strides: note we don't use an inputIndices because we only keep an inputFlatIndex.
	outputIndices := make([]int, rank)
	kernelIndices := make([]int, rank)

	inputStrides := inputShape.Strides()
	kernelStrides := kernelShape.Strides()

	// Loop sequentially over all output positions:
	for outputFlatIdx, outputIndices = range outputShape.IterOn(outputIndices) {
		batchIdx := outputIndices[outputBatchAxis]
		outputChannel := outputIndices[outputChannelsAxis]
		//alt:full|full_bf16  if batchGroupCount > 1 {
		//alt:full|full_bf16  subBatchIdx := outputChannel / batchGroupCount
		//alt:full|full_bf16  batchIdx = subBatchIdx*outputBatchSize + batchIdx
		//alt:full|full_bf16  }
		baseInputFlatIdx := batchIdx * inputStrides[inputBatchAxis]

		// Loop over the kernel spatial axes, with the outputChannel given by the output loop.
		kernelIndices[kernelOutputChannelsAxis] = outputChannel
		//alt:base|full var outputValue T
		var outputValue float32 //alt:bf16|full_bf16
		var kernelFlatIdx int
	kernelLoop:
		for kernelFlatIdx, kernelIndices = range kernelShape.IterOnAxes(kernelSpatialAxes, kernelStrides, kernelIndices) {
			// Calculate the corresponding position in the input.
			inputFlatIdx := baseInputFlatIdx
			for spatialIdx, kernelSpatialAxis := range axes.KernelSpatial {
				kernelIdx := kernelIndices[kernelSpatialAxis]
				//alt:full|full_bf16  kernelDilation := kernelDilations[spatialIdx]
				//alt:full|full_bf16  kernelIdx *= kernelDilation
				outputSpatialAxis := outputSpatialAxes[spatialIdx]
				outputIdx := outputIndices[outputSpatialAxis]
				inputIdx := outputIdx*convStrides[spatialIdx] + kernelIdx - paddings[spatialIdx][0]
				//alt:full|full_bf16  inputDilation := inputDilations[spatialIdx]
				if inputIdx < 0 || inputIdx >= inputSpatialDims[spatialIdx] { //alt:base|bf16
					//alt:full|full_bf16  if inputIdx < 0 || inputIdx >= inputSpatialDims[spatialIdx] || (inputDilation > 1 && inputIdx%inputDilation != 0) {
					// Index is in the padded area, we can move to the next kernel position.
					continue kernelLoop
				}
				//alt:full|full_bf16  inputIdx /= inputDilation // Make the dilated index back to the original input.
				inputFlatIdx += inputIdx * inputSpatialStrides[spatialIdx]
			}

			// Accumulate over all the kernel/input channels.
			inputChannelStride := inputStrides[inputChannelsAxis]
			kernelChannelStride := kernelStrides[kernelInputChannelsAxis]
			//alt:full|full_bf16  if channelGroupCount > 1 {
			//alt:full|full_bf16  featureGroup := outputChannel / numOutputChannelsPerGroup
			//alt:full|full_bf16  inputFlatIdx += inputChannelStride * (featureGroup*kernelNumInputChannels)
			//alt:full|full_bf16  }
			for range kernelNumInputChannels {
				inputValue := inputFlat[inputFlatIdx]
				kernelValue := kernelFlat[kernelFlatIdx]
				//alt:base|full outputValue += inputValue * kernelValue
				outputValue += inputValue.Float32() * kernelValue.Float32() //alt:bf16|full_bf16
				inputFlatIdx += inputChannelStride
				kernelFlatIdx += kernelChannelStride
			}
		}

		// Update output with accumulated value from the convolution of the kernel at this position.
		//alt:base|full outputFlat[outputFlatIdx] = outputValue
		outputFlat[outputFlatIdx] = bfloat16.FromFloat32(outputValue) //alt:bf16|full_bf16
	}
	return nil
}
